{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUgbolxu5quo"
   },
   "source": [
    "# Assignment 4: Keyphrase Extraction, Named Entity Recognition & Neural Models\n",
    "\n",
    "Due: Monday, February 06, 2023, at 2pm via Moodle\n",
    "\n",
    "**Team Members** Jakob Forstmann, Kushal Gaywala, Jonathan Hirsch, Rishab Tiwari\n",
    "\n",
    "Please note that this assignment comes with quite a number of artifacts, totaling somewhere around 5 GB of necessary disk space. In case you are running into issues or do want to keep your environment \"clean\", we suggest the use of [Google Colab](https://colab.research.google.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cmd\n",
    "# . ~/.bashrc\n",
    "python -m pip install keybert\n",
    "python -m pip install git+https://github.com/LIAAD/yake\n",
    "python -m pip install transformers\n",
    "python -m pip install datasets\n",
    "python -m pip install nltk\n",
    "python -m pip install spacy\n",
    "# Install necessary packages for all questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "315kqIiW2Zhr"
   },
   "source": [
    "## Task 1: Keyphrase Extraction (5 + 3 + 3 + 5) = 16 Points\n",
    "\n",
    "In this task, we will implement our own unsupervised keyphrase extraction (KPE) module utilizing a simple grammatical ruling system, which we apply to a Sherlock Holmes novel.\n",
    "To generate TF-IDF-weighted phrases, we will be using the entire collection of Sir Arthur Donan Coyle novels to calculate document frequencies.\n",
    "\n",
    "Finally, we compare the results to general-purpose KPE libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joME4y0pC-bq"
   },
   "source": [
    "### Sub Task 1: Unsupervised Keyphrase Extraction System (5 Points)\n",
    "\n",
    "#### 1. Candidate Generation\n",
    "We will need to generate a set of suitable candidate phrases first, which can then be ranked as keyphrases later on. To do this, we will again be using spaCy's, this time its rule-based [`Matcher` class](https://spacy.io/api/matcher).\n",
    "\n",
    "The syntactic pattern of a keyphrase candidate should satisfy the following rules:\n",
    "\n",
    "1. An optional adjective, noun, proper noun\n",
    "2. An optional adjective, noun, proper noun\n",
    "3. A mandatory noun or proper noun.\n",
    "\n",
    "Add a second pattern, which recognizes the pattern\n",
    "\n",
    "1. A noun or proper noun\n",
    "2. An adposition\n",
    "3. Another noun or proper noun\n",
    "\n",
    "Note that the first condition will match any phrase of length between 1-3 tokens, which is a suitable approximation for our task at hand, whereas the second pattern is slightly more specific, always matching exactly three tokens.\n",
    "An example of a valid matched phrases for the first pattern would be \"Sherlock Holmes\" ([PROPN, PROPN]), and \"Hounds of Baskervilles\" ([NOUN, ADP, PROPN]) for the second pattern."
   ]
  },
  {
   "cell_type": "code",
   
   "execution_count": 10
   "metadata": {
    "id": "j7yKhziiDkzJ"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,

   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1cFJOPt3DlZu",
    "outputId": "a13cb7f2-71ea-49bc-b2cd-b1626cef4789"
   },
   "outputs": [],
   "source": [
    "# load language model\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\"])\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Define the above patterns\n",
    "first_pattern = [ \n",
    "    {\"POS\": {\"IN\": [\"ADJ\", \"PROPN\", \"NOUN\"]}, \"OP\": \"{,2}\"},\n",
    "    {\"POS\": {\"IN\": [\"NOUN\",\"PROPN\"]}},\n",
    "]\n",
    "second_pattern = [\n",
    "    {\"POS\": {\"IN\": [\"NOUN\", \"PROPN\"]}},\n",
    "    {\"POS\": \"ADP\"},\n",
    "    {\"POS\": {\"IN\": [\"NOUN\", \"PROPN\"]}},\n",
    "]\n",
    "\n",
    "matcher.add(\"patterns\", [first_pattern, second_pattern])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify whether your pattern is correct, use the below example.\n",
    "If you have done everything correctly, your matcher will identify **13 phrases**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71JZGbIlHfxx",
    "outputId": "7b650ae4-99bd-4226-ab95-fe0b8cc2b09e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"This is a simple test. It should return 'simple', and 'test', among other phrases. Maybe we can also see if it can recognize the art of war. Would it recognize integer linear programming, too?\")\n",
    "matches = matcher(doc)\n",
    "\n",
    "print(len(matches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3x2TRsI-GeLq"
   },
   "source": [
    "#### 2. Applying Your System\n",
    "\n",
    "Once you have matched the correct number of keyphrase candidates on the above example, apply your rule-based matcher to an actual data sample. We are going to use the Sherlock Holmes novel \"Hounds of Baskervilles\". You can find the raw text file at the following URL:\n",
    "\n",
    "https://sherlock-holm.es/stories/plain-text/houn.txt\n",
    "\n",
    "Download the text from this URL and apply your spaCy model and matcher on it.  \n",
    "**Hint:** Make sure you properly decode your input, since some libraries return binary strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cbDFj7DSLQ5v"
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "def load_txt_from_url(url: str = \"https://sherlock-holm.es/stories/plain-text/houn.txt\") -> str:\n",
    "  with urlopen(url) as text:\n",
    "    data = text.read().decode(\"utf-8\")\n",
    "  return data \n",
    "text = load_txt_from_url()\n",
    "\n",
    "# Apply the spacy model to the loaded text and extract the phrases with the Matcher\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q4U96ELPKtIA"
   },
   "source": [
    "We will now investigate which phrase candidates are the most frequently appearing in this novel, simply based on the phrase frequency. Therefore, convert your abstract match objects into actual strings, lowercase them, and return the 20 most frequently occurring phrase candidates and their respective frequencies.  \n",
    "**Hint:** For counting occurrences, you may look at `collections.Counter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_tGof05SIXES",
    "outputId": "a32bdb06-438d-4268-cdc6-07563c344aab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sir', 350), ('man', 214), ('holmes', 192), ('moor', 159), ('henry', 156), ('sir henry', 135), ('watson', 117), ('baskerville', 116), ('dr.', 109), ('charles', 94), ('stapleton', 93), ('mortimer', 89), ('night', 88), ('time', 86), ('sir charles', 86), ('house', 75), ('face', 75), ('hound', 72), ('barrymore', 72), ('eyes', 71)]\n"
     ]
    }
   ],
   "source": [
    "candidates = []\n",
    "# Lowercase and add the extracted candidate matches to `candidates`\n",
    "for _, start, end in matches:\n",
    "  span = doc[start:end]\n",
    "  candidate_str = span.text.lower()\n",
    "  candidates.append(candidate_str)\n",
    "\n",
    "# Count the number of occurrences of different candidate phrases\n",
    "from collections import Counter\n",
    "candidate_phrases = Counter(candidates)\n",
    "# Print the most frequently occurring phrases, together with the respective frequencies\n",
    "print(candidate_phrases.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYQt8278NA7v"
   },
   "source": [
    "#### 3. Briefly summarize the quality of your top 20 candidates:\n",
    "\n",
    "The most candidates, like 'sir', 'man', or 'face', are actual not really sensible.\n",
    "Only about three of them, namely 'holmes', 'watson', and 'baskerville' are somehow useful.\n",
    "This is probably because the first pattern defined above essentially matches every noun or proper noun and\n",
    "the fact that such a word occurs most often in a text does not indicate that it's an important keyphrases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aucrN3TPJqw1"
   },
   "source": [
    "### Sub Task 2: Generating Document Frequency Values (3 Points)\n",
    "\n",
    "To compare the previously generated terms with a more refined model, we are going to extract document frequencies from the collection of all Sherlock Holmes works. Since the books are relatively long documents, we are instead going to split based on a simple heuristic in the input document, which should allow a decent approximation by taking into account individual chapters of each novel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfp7rUN9N218"
   },
   "source": [
    "1. Start by loading the Sherlock Holmes canon from https://sherlock-holm.es/stories/plain-text/cnus.txt  \n",
    "Afterwards, split the full document into individual chapters. For this, use three consecutive line breaks `\\n\\n\\n` as a splitting condition to approximate the chapters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FJYRCDJyP-Xp",
    "outputId": "e1251116-c0a3-4697-9163-328b10891bf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353\n"
     ]
    }
   ],
   "source": [
    "df_texts = load_txt_from_url(\"https://sherlock-holm.es/stories/plain-text/cnus.txt\")\n",
    "\n",
    "split_df_texts = df_texts.split(\"\\n\\n\\n\")\n",
    "print(len(split_df_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRcMyiKkRU7d"
   },
   "source": [
    "After splitting, you should have 353 individual \"documents\" to work with.\n",
    "\n",
    "2. Now, create a dictionary containing each phrase encountered in the larger corpus, and its associated document frequency. Again, ensure that phrase strings are lowercased for consistency with the previous transformation.  \n",
    "**Hint:** Since the processing of 353 documents might take a while, incorporate [`tqdm.tqdm`](https://tqdm.github.io/) to visualize progress on the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JtXpYkWQQJi2",
    "outputId": "6d2f3743-c8bd-4e76-e676-fc53d1672189"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 353/353 [01:11<00:00,  4.95it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "\n",
    "def return_occurring_phrases(doc_text: str) -> List[str]:\n",
    "  # process text with spaCy and apply the Matcher\n",
    "  doc = nlp(doc_text)\n",
    "  matches = matcher(doc)\n",
    "\n",
    "  # Candidates can be a set, since we only care about the occurrence *once* for IDF values.\n",
    "  # Again, extract the lower-cased text of a matched span.\n",
    "  candidates = set()\n",
    "  for match_id, start, end in matches:\n",
    "    span = doc[start:end]\n",
    "    candidate_str = span.text.lower()\n",
    "    candidates.add(candidate_str)\n",
    "\n",
    "  return list(candidates)\n",
    "\n",
    "all_document_phrases = []\n",
    "# Iterate through the individual documents and extract phrases for them. Use `tqdm` to visualize progress\n",
    "for document in tqdm(split_df_texts):\n",
    "  all_document_phrases += return_occurring_phrases(document)\n",
    "\n",
    "# Once again, count the frequency of term occurrences across all documents\n",
    "all_document_phrases_count = Counter(all_document_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Output the 20 most frequently appearing document phrases that your system detected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7vDTmrTLSY2q",
    "outputId": "6f4b5c46-750f-44f0-b259-f2536034fc17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('man', 112), ('holmes', 107), ('night', 104), ('eyes', 104), ('time', 104), ('face', 102), ('hand', 102), ('sherlock holmes', 101), ('sherlock', 101), ('way', 101), ('matter', 100), ('room', 99), ('mr.', 98), ('hands', 97), ('day', 97), ('case', 96), ('house', 96), ('life', 96), ('one', 95), ('door', 95)]\n"
     ]
    }
   ],
   "source": [
    "print(all_document_phrases_count.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vR9FmhTpS_TB"
   },
   "source": [
    "### Sub Task 3: Generating Weighted Keyphrases (3 Points)\n",
    "\n",
    "We can now incorporate the extracted keyphrases to calculate `tf-idf` scores, and return a hopefully improved version of our keyphrases for the original \"Hounds of Baskervilles\" document. \n",
    "\n",
    "1. Iterate over all phrases occurring in the novel \"Hounds of Baskervilles\", and re-score phrases according to the definition of TF-IDF. Use the smoothed definition of idf:\n",
    "\n",
    "$ idf(t, D) = \\log \\frac{|D|}{|\\{d \\in D : t \\in d\\}| + 1} + 1 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "HDDoPiAATWat"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Dict\n",
    "\n",
    "def tf_idf(tf: int, df_count: int) -> float:\n",
    "  \"\"\"\n",
    "  Computes the TF-IDF scores according to the above-mentioned formula.\n",
    "  Note that you may use a constant for the number of documents (|D|).\n",
    "  \"\"\"\n",
    "  return tf * (math.log(353 / (df_count + 1)) + 1)\n",
    "\n",
    "tf_idf_weighted_candidates = []\n",
    "\n",
    "# Iterate through all candidate phrase/frequency pairs and compute the TF-IDF scores for each phrase\n",
    "# Store the phrase together with its TF-IDF score in `tf_idf_weighted_candidates`\n",
    "for candidate, tf in candidate_phrases.items():\n",
    "  tf_idf_weighted_candidates.append((candidate, tf_idf(tf, all_document_phrases_count[candidate])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mSfTPsukVoEF"
   },
   "source": [
    "2. Now print the top 20 candidate phrases by TF-IDF weight, and compare the results to your previous output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w8ulSamTUsGP",
    "outputId": "c02da910-d190-43f1-b7b7-6016e73da92a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sir', 836.1959348592817), ('moor', 623.6026233649302), ('henry', 588.966394157697), ('sir henry', 552.6737101836245), ('baskerville', 461.2271706883073), ('man', 457.7631709792846), ('holmes', 419.3926713233428), ('stapleton', 400.0412390508737), ('mortimer', 358.9596694460602), ('sir charles', 357.6239356014735), ('charles', 354.8900067360482), ('barrymore', 321.7372404577147), ('dr.', 303.9934368200059), ('watson', 279.5283553672456), ('dr. mortimer', 275.29719676619266), ('hound', 257.0854457468857), ('baronet', 206.4728975746445), ('night', 194.70067819626806), ('hall', 191.75335703217434), ('time', 190.27566278271652)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(tf_idf_weighted_candidates, key=lambda item: item[1], reverse=True)[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kdmGgOThVmyz"
   },
   "source": [
    "3. Write your insights on the comparison of the results below. Try to theorize why some of the phrases still appear, or why other phrases are no longer present:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IDF suppresses phrases that are not especially characteristic for the particular document, i.e. the 'Hounds of Baskervilles' in this case. Therefore, terms like 'house', occuring 75 times in the novel yet being a generally frequent term, does not appear under the top 20 by TF-IDF weight. On the contrary, terms like 'Baskerville' appear often in the novel yet seldom in the other documents, so they aren't suppressed by the IDF so much (relative to other terms, they are even enhanced), so they still appear under the top 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2y8eaRPNWHut"
   },
   "source": [
    "4. Give two examples of how you could further improve the list of keyphrase values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1yfMZ0etWNj_"
   },
   "source": [
    "More sophisticated patterns could be used. The first pattern defined above essentially matches every noun or proper noun. Probably, it should at least be something like adjective - noun.\n",
    "In addition, a phrase could also be weighted according to the position in the text, phrases occuring rather at the begin of a chapter should be weighted stronger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub Task 4: Apply off-the-shelf Keyphrase Extraction Tools (5 Points)\n",
    "\n",
    "To put the findings of your system into context, compare them with two popular open-source libraries, namely [YAKE!](https://github.com/LIAAD/yake) and [KeyBERT](https://github.com/MaartenGr/KeyBERT)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First, start by running the document with YAKE!; you may use the default parameters. Print the resulting keyphrases, which by default returns 20 phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Sir Henry Baskerville', 9.703823247628816e-06), ('Sir Henry', 1.648100191408312e-05), ('Sir Charles Baskerville', 2.0351834688440424e-05), ('Sir Charles', 3.724150731612377e-05), ('Sir', 0.00010788043646785337), ('Sir Charles death', 0.0001335320154208488), ('Henry Baskerville', 0.00020407970787866275), ('Holmes', 0.00027267641332312374), ('Hall Sir Henry', 0.0002827705937659273), ('Baskerville Hall', 0.00030297998752354974), ('Sherlock Holmes', 0.00030366832269808347), ('friend Sir Henry', 0.0003232815192427155), ('Baskerville Hall Sir', 0.00033497855089080193), ('Henry', 0.0003734244162998363), ('Charles Baskerville', 0.00045232284621121374), ('BASKERVILLES Arthur Conan', 0.00046235145087207454), ('asked Sir Henry', 0.0005001869412629496), ('Sir Henry put', 0.0005065910358925609), ('Arthur Conan Doyle', 0.0005408670117356265), ('Baskerville', 0.0005977236792600148)]\n"
     ]
    }
   ],
   "source": [
    "from yake import KeywordExtractor\n",
    "\n",
    "extractor = KeywordExtractor()\n",
    "keywords = extractor.extract_keywords(text)\n",
    "\n",
    "# Print the top 20 keywords\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Compare both runtime efficiency and the extracted phrases with your own system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the one hand, together with the spaCy tokenization, our own system is definetely slower, even without the IDF estimation from all the other documents (taking that into account, YAKE is faster by several orders of magnitude).\n",
    "\n",
    "On the other hand, the results are not so much better: There are some very reasonable keyphrases like the highest rankend 'Sir Henry Baskerville', yet unreasonably the second-ranked keyphrase is a prefix of the first one. The same is true for the third and the fourth result. If such prefixes, suffixes and the like would be filtered out, the YAKE results would be probably much better than those of our system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Now use the KeyBERT library to extract keyphrases. Importantly, you will need to split the document into separate paragraphs, as the underlying neural model will be unable to handle the complete document as input.  \n",
    "Use the pattern of `\\n\\n` to separate the text into smaller paragraphs, and filter out any empty lines after. An \"empty line\" also constitutes all inputs that only contain newline (`\\n`) or whitespace ` ` characters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the input text according to the specified criteria and filter empty lines out.\n",
    "split_text = [p for p in text.split(\"\\n\\n\") if p.strip(\" \\n\") != \"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. To ensure consistency between the tools when extracting keyphrases, set the *n*-gram range to `(1,3)`.\n",
    "Otherwise, leave all parameters at the default value, and extract the keyphrases from each paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyBERT\n",
    "\n",
    "# This might take a while to install\n",
    "model = KeyBERT(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the keyphrases from each split, using the adjusted keyphrase ngram range\n",
    "# Hint: You may pass a list to the extraction function and KeyBERT will automatically handle iteration.\n",
    "extracted_phrases = model.extract_keywords(split_text, keyphrase_ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Combine the predictions of all individual splits into a single list. For this, sum up the prediction scores across all splits.  \n",
    "**Hint:** `collections.defaultdict` makes aggregations like this much easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from collections import defaultdict\n",
    "\n",
    "def merge_predictions(list_of_predictions: List[List[Tuple]]) -> List[Tuple]:\n",
    "    \"\"\"\n",
    "    Combines lists of predictions into a single list with added scores.\n",
    "    \"\"\"\n",
    "    phrase_dict = defaultdict(int)\n",
    "\n",
    "    # Iterate through all the lists of predictions and add the scores to the correct dict entry\n",
    "    for paragraph_list in list_of_predictions:\n",
    "      for keyphrase, score in paragraph_list:\n",
    "        phrase_dict[keyphrase] += score\n",
    "\n",
    "    # Extract the 20 keyphrases with the highest weithgts from `phrase_dict`\n",
    "    phrase_list = Counter(phrase_dict).most_common(20)\n",
    "\n",
    "    return phrase_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sir henry', 30.826300000000003), ('holmes', 30.425000000000004), ('dr mortimer', 24.266699999999997), ('mortimer', 22.4), ('watson', 21.2683), ('sir charles', 17.5742), ('said holmes', 16.1206), ('sherlock holmes', 15.2558), ('barrymore', 13.793199999999999), ('dr watson', 12.346900000000002), ('mr holmes', 10.4943), ('sir', 10.3469), ('moor', 10.3131), ('mr sherlock holmes', 8.103), ('hound', 7.942399999999999), ('sir henry baskerville', 7.7776), ('henry', 7.257099999999999), ('baskerville hall', 5.9735000000000005), ('sherlock', 5.7341999999999995), ('yes', 5.649700000000001)]\n"
     ]
    }
   ],
   "source": [
    "print(merge_predictions(extracted_phrases))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Again, evaluate the result and compare it to the other two approaches in terms of extraction quality and extraction speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KeyBERT takes way longer than YAKE and and than our own system without IDF weighting, but is faster than our system with the later improvement.\n",
    "\n",
    "The extraction quality is a comparable to our system. YAKE is probably better: For example, the highest scored result of KeyBERT is 'Sir Henry' which is rather useless whereas it is 'Sir Henry Baskerville' in case of YAKE. The latter keyphrase is found by KeyBERT as well but only as the 16th result. In addition, KeyBERT found totally useless phrases such as 'yes' among the top 20 (yet as the last one of them)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Named Entity Recognition (4 + 5 + 5 = 14 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly different, but still operating on the sequence level, is the task of Named Entity Recognition (NER).\n",
    "In this task, we will evaluate the NER capabilities of some more open-source libraries.\n",
    "Particularly, we will also evaluate the utility of NER as a stand-in for Keyphrase Extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub Task 1: Using spaCy NER (4 Points)\n",
    "\n",
    "So far, when using spaCy models, we have primarily disabled the NER component, as it requires significant extra compute.\n",
    "In this task, we will explicitly leave the component enabled, to see what results it can produce on the text from the previous question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the en_core_web_sm model, but with NER enabled.\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Re-load the text for the \"Hounds of Baskervilles\" novel, and run it with the spacy model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-use the function from the previous exercise.\n",
    "text = load_txt_from_url()\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Similar to the previous exercise, count the number of occurrences, however, this time for the extracted entities instead of phrases. Print the top 20 most frequently occurring entities.  \n",
    "Make sure to lowercase the text again during your aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(Holmes, 151), (Henry, 117), (Watson, 104), (one, 77), (Charles, 74), (Stapleton, 73), (Mortimer, 72), (two, 59), (London, 49), (first, 48), (Barrymore, 43), (Baskerville, 34), (Baskerville Hall, 28), (Sherlock Holmes, 24), (Henry Baskerville, 20), (half, 20), (One, 19), (night, 17), (Coombe Tracey, 16), (second, 15)]\n"
     ]
    }
   ],
   "source": [
    "# Count the number of occurrences of particular entities\n",
    "entities = doc.ents\n",
    "entities_count = []\n",
    "for entity in entities:\n",
    "    count = 0\n",
    "    exists = False\n",
    "    for ent_cnt in entities_count:\n",
    "        if str(entity) == str(ent_cnt[0]):\n",
    "            exists = True\n",
    "    if exists:\n",
    "        continue\n",
    "    for ent in entities:\n",
    "        if str(entity) == str(ent):\n",
    "            count += 1 \n",
    "    entities_count.append((entity, count))\n",
    "\n",
    "# Print the top 20 most frequently occurring entities.\n",
    "print(sorted(entities_count, key=lambda x: x[1], reverse=True)[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might have noticed some unwanted results in the list, such as \"night\". Upon closer inspection, it turns out that the NER module further differentiates between different entity *categories*, such as PERSON (referencing, as expected, a physical person) or ORG (organizations, such as companies, NGOs, etc.), but also TIME (under which \"night\" falls). For reference, you can find the full list of supported NER labels by this particular model [here](https://spacy.io/models/en#en_core_web_sm-labels).\n",
    "\n",
    "3. Refine the list of most common entities by printing out the top three occurring entities in the category `PERSON`, `ORG` and `GPE` (physical locations) instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({Arthur: 1, Conan: 1, Doyle: 1, Sherlock: 1, Holmes: 1, Henry: 1, Baskerville: 1, Baskerville: 1, Hall: 1, \n",
      "        : 1, The: 1, Stapletons: 1, of: 1, Merripit: 1, House: 1, Watson: 1, Watson: 1, Sherlock: 1, Holmes: 1, Sherlock: 1, Holmes: 1, James: 1, Mortimer: 1, Holmes: 1, Watson: 1, Mortimer: 1, Holmes: 1, Holmes: 1, Holmes: 1, Watson: 1, Watson: 1, Watson: 1, James: 1, Winner: 1, Jackson: 1, Watson: 1, Holmes: 1, Jove: 1, Watson: 1, Watson: 1, James: 1, \n",
      "     : 1, Mortimer: 1, Holmes: 1, Holmes: 1, Holmes: 1, Mortimer: 1, Holmes: 1, James: 1, Mortimer--: 1, Holmes: 1, Sherlock: 1, Holmes: 1, Watson: 1, Holmes: 1, Holmes: 1, Holmes: 1, Holmes: 1, Holmes: 1, Mortimer: 1, James: 1, Mortimer: 1, Holmes: 1, Mortimer: 1, Charles: 1, Baskerville: 1, Holmes: 1, Watson: 1, Baskerville: 1, Hall: 1, Baskerville: 1, Mortimer: 1, Hugo: 1, Baskerville: 1, Clarendon: 1, Hugo: 1, Baskerville: 1, Hugo: 1, Baskerville: 1, Hugo: 1, Baskerville: 1, Hugo: 1, Baskerville: 1, Providence: 1, Hugo: 1, Baskerville: 1, Rodger: 1, John: 1, Elizabeth: 1, Mortimer: 1, Mortimer: 1, Holmes: 1, Charles: 1, \n",
      "     : 1, Baskerville: 1, Charles: 1, Baskerville: 1, Charles: 1, Charles: 1, Charles: 1, Charles: 1, Barrymore: 1, Charles: 1, James: 1, Mortimer: 1, Charles: 1, Baskerville: 1, Yew: 1, \n",
      "     : 1, Alley: 1, Charles: 1, Barrymore: 1, Charles: 1, Charles: 1, Barrymore: 1, gipsy: 1, Charles: 1, Mortimer: 1, Charles: 1, Hall: 1, Henry: 1, Baskerville: 1, Charles: 1, Baskerville: 1, 's: 1, Mortimer: 1, Holmes: 1, Charles: 1, Baskerville: 1, Sherlock: 1, Holmes: 1, Mortimer: 1, Charles: 1, Baskerville: 1, Frankland: 1, Stapleton: 1, Charles: 1, Bushman: 1, Charles: 1, Holmes: 1, Charles: 1, Charles: 1, Baskerville: 1, Hall: 1, Charles: 1, Mortimer: 1, Holmes: 1, Holmes: 1, Charles: 1, Mortimer: 1, Charles: 1, Watson: 1, Mortimer: 1, Mortimer: 1, Holmes: 1, Holmes: 1, Holmes: 1, Mortimer: 1, Charles: 1, Henry: 1, Baskerville: 1, Charles: 1, Charles: 1, Rodger: 1, Baskerville: 1, Henry: 1, Henry: 1, Waterloo: 1, Station: 1, Holmes: 1, Baskerville: 1, Charles: 1, Charles: 1, Holmes: 1, Holmes: 1, Waterloo: 1, Henry: 1, Baskerville: 1, Mortimer: 1, Henry: 1, \n",
      "     : 1, Baskerville: 1, Holmes: 1, Holmes: 1, Mortimer: 1, Charles: 1, Baskerville: 1, 's: 1, Holmes: 1, Watson: 1, Bradley: 1, Watson: 1, Holmes: 1, Watson: 1, Baskerville: 1, Hall: 1, Yew: 1, Alley: 1, Mortimer: 1, Lafter: 1, Hall: 1, Mortimer: 1, Watson: 1, Yew: 1, Alley: 1, Watson: 1, Mortimer: 1, Henry: 1, Baskerville: 1, Henry: 1, Baskerville: 1, Holmes: 1, Henry: 1, Baskerville: 1, Mortimer: 1, Sherlock: 1, Holmes: 1, Henry: 1, Holmes: 1, Henry: 1, \n",
      "     : 1, Baskerville: 1, Holmes: 1, Mortimer: 1, Mortimer: 1, Henry: 1, Baskerville: 1, Holmes: 1, Mortimer: 1, Henry: 1, Henry: 1, Sherlock: 1, Holmes: 1, Watson: 1, Watson: 1, Holmes: 1, Mortimer: 1, Henry: 1, Baskerville: 1, Watson: 1, Watson: 1, Holmes: 1, Mortimer: 1, Leeds: 1, Mercury: 1, Holmes: 1, Henry: 1, \n",
      "     : 1, Baskerville: 1, Holmes: 1, Holmes: 1, Holmes: 1, Henry: 1, Henry: 1, Holmes: 1, Henry: 1, Mortimer: 1, Holmes: 1, Mortimer: 1, Sherlock: 1, Holmes: 1, Mortimer: 1, Holmes: 1, Henry: 1, Baskerville: 1, Mortimer: 1, Holmes: 1, Mortimer: 1, Henry: 1, Holmes: 1, Holmes: 1, Watson: 1, Holmes: 1, Watson: 1, Mortimer: 1, Baskerville: 1, Watson: 1, Watson: 1, Holmes: 1, Watson: 1, Watson: 1, Mortimer: 1, Watson: 1, Watson: 1, Mortimer: 1, Holmes: 1, Watson: 1, Cartwright: 1, Holmes: 1, Watson: 1, Henry: 1, Baskerville: 1, Holmes: 1, Baskerville: 1, Theophilus: 1, Johnson: 1, Oldmore: 1, Johnson: 1, Holmes: 1, Johnson: 1, Oldmore: 1, Gloucester: 1, Watson: 1, Henry: 1, Baskerville: 1, Holmes: 1, Holmes: 1, Holmes: 1, Henry: 1, Holmes: 1, Mortimer: 1, Mortimer: 1, Charles: 1, Barrymore: 1, Henry: 1, Barrymore: 1, Baskerville: 1, Hall: 1, Barrymore: 1, Henry: 1, \n",
      "     : 1, Baskerville: 1, Barrymore: 1, Baskerville: 1, Mortimer: 1, Baskerville: 1, Hall: 1, Barrymore: 1, Charles: 1, Holmes: 1, Charles: 1, Mortimer: 1, Charles: 1, Henry: 1, Charles: 1, Mortimer: 1, Charles: 1, James: 1, Desmond: 1, James: 1, Desmond: 1, Charles: 1, Charles: 1, Charles: 1, Henry: 1, Holmes: 1, Henry: 1, Mortimer: 1, Mortimer: 1, Henry: 1, Holmes: 1, Watson: 1, Holmes: 1, I.: 1, Holmes: 1, Watson: 1, Baskerville: 1, Sherlock: 1, Holmes: 1, Mortimer: 1, Baskerville: 1, Charles: 1, Barrymore: 1, Baskerville: 1, Watson: 1, Holmes: 1, John: 1, Clayton: 1, Waterloo: 1, Station: 1, Sherlock: 1, Holmes: 1, Watson: 1, Sherlock: 1, Holmes: 1, Holmes: 1, Holmes: 1, Sherlock: 1, Holmes: 1, Sherlock: 1, Holmes: 1, John: 1, Clayton: 1, Holmes: 1, Henry: 1, \n",
      "     : 1, Baskerville: 1, Watson: 1, Watson: 1, Henry: 1, Baskerville: 1, Mortimer: 1, Sherlock: 1, Holmes: 1, Watson: 1, Baskerville: 1, James: 1, Desmond: 1, Henry: 1, Baskerville: 1, Barrymore: 1, Mortimer: 1, Stapleton: 1, Frankland: 1, Mortimer: 1, Baskerville: 1, Holmes: 1, Henry: 1, Henry: 1, Mortimer: 1, Holmes: 1, Mortimer: 1, Young: 1, Baskerville: 1, Devon: 1, Mortimer: 1, Charles: 1, Baskerville: 1, Hall: 1, Watson: 1, Mortimer: 1, Baskerville: 1, Henry: 1, Baskerville: 1, Baskerville: 1, Mortimer: 1, Perkins: 1, Mortimer: 1, Holmes: 1, craggy: 1, cairns: 1, Baskerville: 1, Baskerville: 1, Hall: 1, Charles: 1, Baskerville: 1, Yew: 1, Alley: 1, Henry: 1, Henry: 1, Barrymore: 1, Henry: 1, Henry: 1, Henry: 1, Henry: 1, Charles: 1, Charles: 1, Charles: 1, Henry: 1, Henry: 1, Barrymore: 1, Henry: 1, Barrymore: 1, Charles: 1, Barrymore: 1, Henry: 1, Mortimer: 1, James: 1, Barrymore: 1, Barrymore: 1, Barrymore: 1, Barrymore: 1, Holmes: 1, Barrymore: 1, Charles: 1, Baskerville: 1, Henry: 1, Holmes: 1, Mortimer: 1, Watson: 1, Mortimer: 1, Stapleton: 1, Stapleton: 1, Mortimer: 1, Henry: 1, Charles: 1, Henry: 1, Charles: 1, Mortimer: 1, Charles: 1, Sherlock: 1, Holmes: 1, Mortimer: 1, Sherlock: 1, Holmes: 1, Stapleton: 1, Merripit: 1, House: 1, Henry: 1, Holmes: 1, Stapleton: 1, Charles: 1, George: 1, Watson: 1, Stapleton: 1, Merripit: 1, House: 1, Stapleton: 1, Stapleton: 1, Hush: 1, Jack: 1, Henry: 1, Henry: 1, Baskerville: 1, Watson: 1, Watson: 1, Beryl: 1, Stapleton: 1, Watson: 1, Mortimer: 1, Charles: 1, Watson: 1, Lepidoptera: 1, Miss: 1, Stapleton: 1, Stapleton: 1, Watson: 1, Henry: 1, Miss: 1, Stapleton: 1, Henry: 1, Henry: 1, Watson: 1, Miss: 1, Stapleton: 1, Henry: 1, Watson: 1, Charles: 1, Henry: 1, Henry: 1, Stapleton: 1, Watson: 1, Sherlock: 1, Holmes: 1, Holmes: 1, hairy: 1, man: 1, crawl: 1, Henry: 1, Baskerville: 1, Henry: 1, Stapleton: 1, Henry: 1, Stapleton: 1, Henry: 1, Stapleton: 1, Stapleton: 1, Henry: 1, Mortimer: 1, Yew: 1, Alley: 1, Yew: 1, Alley: 1, Fernworthy: 1, Mortimer: 1, Neolithic: 1, Mortimer: 1, Frankland: 1, Barrymore: 1, Henry: 1, Barrymore: 1, Henry: 1, Henry: 1, Henry: 1, Barrymore: 1, Watson: 1, Holmes: 1, Barrymore: 1, Barrymore: 1, Barrymore: 1, Barrymore: 1, Holmes: 1, I.: 1, Barrymore: 1, Henry: 1, Charles: 1, Stapleton: 1, Barrymore: 1, Henry: 1, Watson: 1, Holmes: 1, Henry: 1, Holmes: 1, Henry: 1, Stapleton: 1, Henry: 1, Stapleton: 1, Henry: 1, Stapleton: 1, Stapleton: 1, Henry: 1, Stapleton: 1, Watson: 1, Watson: 1, Watson: 1, Stapleton: 1, Henry: 1, Henry: 1, Stapleton: 1, Henry: 1, Barrymore: 1, Holmes: 1, Henry: 1, Barrymore: 1, Henry: 1, Barrymore: 1, Barrymore: 1, Henry: 1, Henry: 1, I.: 1, Watson: 1, John: 1, John: 1, is--: 1, Barrymore: 1, Henry: 1, Barrymore: 1, Henry: 1, Henry: 1, Henry: 1, Barrymore: 1, Watson: 1, Henry: 1, Watson: 1, Holmes: 1, Watson: 1, Watson: 1, Watson: 1, Watson: 1, Watson: 1, Watson: 1, Henry: 1, Barrymore: 1, Henry: 1, Holmes: 1, Holmes: 1, Watson: 1, Mortimer: 1, Henry: 1, Stapleton: 1, Henry: 1, Henry: 1, Stapleton: 1, Henry: 1, Watson: 1, Henry: 1, Watson: 1, Barrymore: 1, Henry: 1, Charles: 1, L.: 1, L.: 1, Barrymore: 1, Henry: 1, Coombe: 1, Tracey: 1, Charles: 1, L.: 1, L.: 1, Charles: 1, L.: 1, L.: 1, Charles: 1, Charles: 1, L.: 1, L.: 1, Holmes: 1, Baskerville: 1, Hall: 1, Mortimer: 1, Mortimer: 1, L.: 1, \n",
      "     : 1, L.: 1, Laura: 1, Lyons: 1, Coombe: 1, Tracey: 1, Frankland: 1, Lyons: 1, Frankland: 1, Coombe: 1, Tracey: 1, Laura: 1, Lyons: 1, Mortimer: 1, Frankland: 1, Henry: 1, Charles: 1, Henry: 1, Selden: 1, Coombe: 1, Tracey: 1, Laura: 1, Lyons: 1, Charles: 1, \n",
      "     : 1, Baskerville: 1, Lyons: 1, Mortimer: 1, Coombe: 1, Tracey: 1, Henry: 1, Coombe: 1, Tracey: 1, Remington: 1, Lyons: 1, Charles: 1, Baskerville: 1, Charles: 1, Baskerville: 1, Charles: 1, Coombe: 1, Tracey: 1, Stapleton: 1, Charles: 1, Charles: 1, Charles: 1, Baskerville: 1, Stapleton: 1, Charles: 1, Lyons: 1, Charles: 1, I.: 1, Charles: 1, Charles: 1, Charles: 1, Charles: 1, Charles: 1, Charles: 1, Charles: 1, Charles: 1, Baskerville: 1, Hall: 1, Holmes: 1, Frankland: 1, Watson: 1, Perkins: 1, Henry: 1, Frankland: 1, Middleton: 1, Fernworthy: 1, Watson: 1, John: 1, Morland: 1, Frankland: 1, Fernworthy: 1, Barrymore: 1, Barrymore: 1, Frankland: 1, Watson: 1, Frankland: 1, Watson: 1, Stapleton: 1, Watson: 1, Coombe: 1, Tracey: 1, Henry: 1, Watson: 1, Holmes: 1, Watson: 1, Watson: 1, Watson: 1, Coombe: 1, Tracey: 1, Laura: 1, Lyons: 1, Holmes: 1, Henry: 1, Holmes: 1, Holmes: 1, Laura: 1, Lyons: 1, Coombe: 1, Tracey: 1, Holmes: 1, Stapleton: 1, Stapleton: 1, Holmes: 1, Henry: 1, Henry: 1, Henry: 1, Holmes: 1, Laura: 1, Lyons: 1, Stapleton: 1, Watson: 1, Holmes: 1, Watson: 1, Henry: 1, Holmes: 1, Holmes: 1, Watson: 1, Holmes: 1, Holmes: 1, Watson: 1, Watson: 1, Holmes: 1, Holmes: 1, Henry: 1, Baskerville: 1, Holmes: 1, Holmes: 1, Watson: 1, Stapleton: 1, Henry: 1, Holmes: 1, Barrymore: 1, Henry: 1, Holmes: 1, Henry: 1, Watson: 1, Henry: 1, Henry: 1, Henry: 1, Holmes: 1, Stapleton: 1, Sherlock: 1, Holmes: 1, Watson: 1, Holmes: 1, Holmes: 1, Holmes: 1, Watson: 1, Watson: 1, Charles: 1, Charles: 1, Laura: 1, Lyons: 1, Henry: 1, Selden: 1, Stapleton: 1, Henry: 1, Sherlock: 1, Holmes: 1, Barrymore: 1, Watson: 1, Stapleton: 1, Holmes: 1, Henry: 1, Watson: 1, Watson: 1, Watson: 1, Watson: 1, Henry: 1, Baskerville: 1, Rodney: 1, William: 1, Baskerville: 1, Pitt: 1, Holmes: 1, Henry: 1, Henry: 1, Stapleton: 1, Watson: 1, Holmes: 1, Henry: 1, Holmes: 1, Watson: 1, Watson: 1, Coombe: 1, Tracey: 1, Watson: 1, Watson: 1, Stapleton: 1, Holmes: 1, Stapleton: 1, Henry: 1, Baskerville: 1, Holmes: 1, Lestrade: 1, Watson: 1, Laura: 1, Lyons: 1, Henry: 1, Laura: 1, Lyons: 1, Charles: 1, Baskerville: 1, Watson: 1, Charles: 1, Lyons: 1, Stapleton: 1, Lyons: 1, Holmes: 1, Vandeleur: 1, Vandeleur: 1, Holmes: 1, Sherlock: 1, Holmes: 1, Stapleton: 1, Charles: 1, Holmes: 1, Anderson: 1, Lestrade: 1, Holmes: 1, Lestrade: 1, Holmes: 1, Hall: 1, Coombe: 1, Tracey: 1, Lestrade: 1, Holmes: 1, Merripit: 1, House: 1, Holmes: 1, Lestrade: 1, Watson: 1, Henry: 1, Stapleton: 1, Stapleton: 1, Henry: 1, Watson: 1, Holmes: 1, Holmes: 1, Watson: 1, Holmes: 1, Holmes: 1, God: 1, Holmes: 1, Lestrade: 1, Holmes: 1, Henry: 1, Holmes: 1, Henry: 1, Holmes: 1, Henry: 1, Holmes: 1, Holmes: 1, Holmes: 1, Henry: 1, Holmes: 1, Holmes: 1, Lestrade: 1, Holmes: 1, Stapleton: 1, Holmes: 1, Lestrade: 1, Henry: 1, Holmes: 1, Holmes: 1, Lestrade: 1, Holmes: 1, Mortimer: 1, Henry: 1, Stapleton: 1, Henry: 1, Stapleton: 1, Stapleton: 1, Holmes: 1, Jove: 1, Mortimer: 1, Charles: 1, Watson: 1, Holmes: 1, Upwood: 1, Mme: 1, Baskerville: 1, Henry: 1, Mortimer: 1, Holmes: 1, Stapleton: 1, Stapleton: 1, Rodger: 1, Baskerville: 1, Charles: 1, Beryl: 1, Garcia: 1, Fraser: 1, Vandeleurs: 1, Stapleton: 1, Charles: 1, Baskerville: 1, Mortimer: 1, Charles: 1, Ross: 1, Mangles: 1, Stapleton: 1, Charles: 1, Charles: 1, Lyons: 1, Coombe: 1, Tracey: 1, Mortimer: 1, Charles: 1, Baskerville: 1, Stapleton: 1, Laura: 1, Lyons: 1, Stapleton: 1, Stapleton: 1, Lyons: 1, Stapleton: 1, Mortimer: 1, Henry: 1, Baskerville: 1, Stapleton: 1, Stapleton: 1, Stapleton: 1, Stapleton: 1, Stapleton: 1, Stapleton: 1, Anthony: 1, Anthony: 1, Antonio: 1, Stapleton: 1, Stapleton: 1, Henry: 1, Stapleton: 1, Stapleton: 1, Coombe: 1, Tracey: 1, Stapleton: 1, Stapleton: 1, Henry: 1, Henry: 1, Stapleton: 1, Henry: 1, Stapleton: 1, Henry: 1, Stapleton: 1, Henry: 1, Henry: 1, Henry: 1, Watson: 1, Henry: 1, Stapleton: 1, Stapleton: 1, Watson: 1, Les: 1, Huguenots: 1, Marcini: 1})\n",
      "[Marcini, Huguenots, Les]\n",
      "Counter({Problem: 1, C.C.H.: 1, C.C.H.: 1, Charing: 1, Cross: 1, ': 1, C.C.H.: 1, Charing: 1, Cross: 1, \n",
      "     : 1, Hospital: 1, Sherlock: 1, Holmes: 1, the: 1, Medical: 1, Directory: 1, Grimpen: 1, Devon: 1, House: 1, Charing: 1, Cross: 1, Hospital: 1, Comparative: 1, Pathology: 1, Lancet: 1, \n",
      "     : 1, 1882: 1, Journal: 1, of: 1, Psychology: 1, Grimpen: 1, ,: 1, Thorsley: 1, Sherlock: 1, Holmes: 1, Charing: 1, Cross: 1, Hospital: 1, Monsieur: 1, \n",
      "     : 1, Bertillon: 1, Justice: 1, a: 1, \n",
      "     : 1, yeoman: 1, the: 1, Devon: 1, County: 1, Chronicle: 1, Liberal: 1, Mid: 1, -: 1, Devon: 1, Alley: 1, Alley: 1, Baskerville: 1, \n",
      "     : 1, Hall: 1, Hottentot: 1, Problem: 1, Alley: 1, yew: 1, besides--: 1, Rodger: 1, Baker: 1, Street: 1, Northumberland: 1, Hotel: 1, the: 1, Northumberland: 1, Hotel: 1, Times: 1, Esquimau: 1, crest: 1, Times: 1, Esquimau: 1, the: 1, Western: 1, Morning: 1, News: 1, Times: 1, Times: 1, Charing: 1, Cross: 1, Times: 1, Oxford: 1, Street: 1, Oxford: 1, Street: 1, Holmes: 1, the: 1, Northumberland: 1, Hotel: 1, Wilson: 1, Wilson: 1, the: 1, Hotel: 1, Directory: 1, Charing: 1, Cross: 1, Times: 1, Times: 1, Times: 1, Baker: 1, Street: 1, Bond: 1, \n",
      "     : 1, Street: 1, the: 1, \n",
      "     : 1, Northumberland: 1, Hotel: 1, High: 1, Lodge: 1, Telegram: 1, Northumberland: 1, Hotel: 1, Holmes: 1, Westmoreland: 1, House: 1, I.: 1, Baker: 1, Street: 1, Times: 1, Official: 1, \n",
      "     : 1, Registry: 1, Borough: 1, Shipley: 1, Clayton: 1, the: 1, Northumberland: 1, Hotel: 1, Baker: 1, Street: 1, Baker: 1, Street: 1, CHAPTER: 1, VI: 1, \n",
      "          : 1, the: 1, Museum: 1, of: 1, the: 1, \n",
      "     : 1, College: 1, of: 1, Surgeons: 1, melancholy: 1, hill: 1, Edison: 1, I.: 1, Good: 1, -: 1, bye: 1, Regency: 1, Grimpen: 1, Sherlock: 1, Holmes: 1, Hall: 1, Times: 1, Grimpen: 1, Mire: 1, Grimpen: 1, Mire: 1, I.: 1, Halloa: 1, ,: 1, Beryl: 1, I.: 1, I.: 1, Grimpen: 1, Mire: 1, MOOR: 1, Plymouth: 1, I.: 1, Miss: 1, \n",
      "     : 1, Stapleton: 1, Eliza: 1, fed: 1, I.: 1, Grimpen: 1, Mire: 1, Grimpen: 1, Mire: 1, the: 1, \n",
      "     : 1, hill: 1, Sherlock: 1, Holmes: 1, Baker: 1, Street: 1, I.: 1, Coombe: 1, \n",
      "     : 1, Tracey: 1, Morland: 1, ,: 1, Court: 1, of: 1, Queen: 1, 's: 1, Bench: 1, I.: 1, Black: 1, Tor: 1, Belliver: 1, and: 1, Vixen: 1, Tor: 1, Neolithic: 1, Grimpen: 1, Mire: 1, Bradley: 1, Oxford: 1, Street: 1, Holmes: 1, Grimpen: 1, Halloa: 1, ,: 1, Watson: 1, I.: 1, Reynolds: 1, Cavalier: 1, Holmes: 1, Baker: 1, Street: 1, Grimpen: 1, Merripit: 1, \n",
      "     : 1, House: 1, Coombe: 1, Tracey: 1, Baker: 1, Street: 1, Sherlock: 1, Holmes: 1, Mrs.: 1, \n",
      "     : 1, Lyons: 1, Dartmoor: 1, Sherlock: 1, Holmes: 1, 's: 1, Frankland: 1, Grimpen: 1, Mire: 1, Holmes: 1, Grimpen: 1, Mire: 1, Grimpen: 1, Mire: 1, XV: 1, \n",
      "          : 1, Baker: 1, \n",
      "     : 1, Street: 1, the: 1, Nonpareil: 1, Club: 1, Upwood: 1, Vandeleur: 1, the: 1, British: 1, Museum: 1, Vandeleur: 1, the: 1, Grimpen: 1, Mire: 1, Laura: 1, Lyons: 1, Mexborough: 1, \n",
      "     : 1, Private: 1, Hotel: 1, Baker: 1, Street: 1, the: 1, \n",
      "     : 1, Northumberland: 1, Hotel: 1, Folkestone: 1, Court: 1, I.: 1, the: 1, Grimpen: 1, Mire: 1, Coombe: 1, Tracey: 1, Baker: 1, Street: 1, the: 1, De: 1, Reszkes: 1, ASCII: 1, HTML: 1})\n",
      "[HTML, ASCII, Reszkes]\n",
      "Counter({Penang: 1, M.R.C.S.: 1, London: 1, M.R.C.S.: 1, London: 1, M.R.C.S.: 1, Devonshire: 1, Baskerville: 1, Baskerville: 1, Michaelmas: 1, Providence: 1, Holy: 1, Writ: 1, England: 1, London: 1, America: 1, South: 1, Africa: 1, London: 1, Baskerville: 1, Canada: 1, Baskerville: 1, England: 1, Southampton: 1, Baskerville: 1, London: 1, Devonshire: 1, Devonshire: 1, London: 1, Holmes: 1, Devonshire: 1, Stamford: 1, Princetown: 1, London: 1, London: 1, Holmes: 1, London: 1, States: 1, Canada: 1, Strand: 1, London: 1, Baskerville: 1, Baskerville: 1, Newcastle: 1, Alton: 1, perhaps--: 1, Holmes: 1, Baskerville: 1, London: 1, London: 1, Devonshire: 1, Devonshire: 1, London: 1, England: 1, Baskerville: 1, Paddington: 1, London: 1, Devonshire: 1, Devonshire: 1, Devonshire: 1, America: 1, Princetown: 1, Selden: 1, Baskerville: 1, London: 1, England: 1, England: 1, Cyclopides: 1, England: 1, London: 1, London: 1, Cyclopides: 1, England: 1, London: 1, England: 1, Notting: 1, Hill: 1, Baskerville: 1, Long: 1, Down: 1, London: 1, London: 1, London: 1, Selden: 1, London: 1, Princetown: 1, London: 1, London: 1, Frankland: 1, London: 1, Selden: 1, London: 1, Baskerville: 1, London: 1, hill: 1, London: 1, The: 1, County: 1, Constabulary: 1, Frankland: 1, Frankland: 1, Grimpen: 1, London: 1, England: 1, Selden: 1, Barrymore: 1, Selden: 1, Selden: 1, Selden: 1, Princetown: 1, Holmes: 1, London: 1, London: 1, Baskerville: 1, London: 1, Baskerville: 1, Princetown: 1, London: 1, London: 1, Devonshire: 1, London: 1, London: 1, London: 1, York: 1, St.: 1, \n",
      "     : 1, Oliver: 1, 's: 1, Godno: 1, Little: 1, \n",
      "     : 1, Russia: 1, North: 1, Carolina: 1, London: 1, London: 1, peaty: 1, Toronto: 1, London: 1, Devonshire: 1, Mlle: 1, New: 1, York: 1, London: 1, Mlle: 1, Baskerville: 1, Costa: 1, Rica: 1, England: 1, Yorkshire: 1, England: 1, Devonshire: 1, London: 1, London: 1, Canada: 1, Canada: 1, London: 1, Devonshire: 1, London: 1, Baskerville: 1, West: 1, Country: 1, London: 1, London: 1, England: 1, Devonshire: 1, London: 1, England: 1, London: 1})\n",
      "[London, England, London]\n"
     ]
    }
   ],
   "source": [
    "def get_top_entities_by_class(doc: spacy.tokens.Doc, class_name: str, n: int = 3) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Returns the three most frequent entities (and their frequencies)\n",
    "    of entity type `class_name` from `doc`.\n",
    "    \"\"\"\n",
    "    # Extract phrase and frequency of a particular entity class\n",
    "    # counter = []\n",
    "\n",
    "    # for phrase in doc:\n",
    "    #     if phrase.ent_type_ != class_name:\n",
    "    #         continue\n",
    "    #     count = 0\n",
    "    #     exists = False\n",
    "    #     for ent_cnt in counter:\n",
    "    #         if str(phrase) == str(ent_cnt[0]):\n",
    "    #             exists = True\n",
    "    #     if exists:\n",
    "    #         continue\n",
    "    #     for ent in entities:\n",
    "    #         if str(phrase) == str(ent):\n",
    "    #             count += 1 \n",
    "    #     counter.append((phrase, count))\n",
    "    counter = Counter([phrase for phrase in doc if phrase.ent_type_ == class_name])\n",
    "\n",
    "    # Return the top 3 entities and frequencies\n",
    "    print(counter)\n",
    "    return sorted(counter, key=lambda x: x, reverse=True)[:n]\n",
    "\n",
    "\n",
    "# Print the results for \"PERSON\", \"ORG\" and \"GPE\"\n",
    "print(get_top_entities_by_class(doc, \"PERSON\", 3))\n",
    "print(get_top_entities_by_class(doc, \"ORG\", 3))\n",
    "print(get_top_entities_by_class(doc, \"GPE\", 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub Task 2: Financial Bank Statements of Deutsche Bank (5 Points)\n",
    "\n",
    "Instead of using the Sherlock Holmes Novels, we will now compare the functionality of spaCy and NLTK's NER modules on the financial statements of Deutsche Bank from 2021. For this, see the file available on Moodle.\n",
    "\n",
    "1. Download it and convert the PDF document into text, by using the `pdftotext` command-line utility. In particular, run with the `-layout` option enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    ". ~/.bashrc\n",
    "## YOUR SHELL COMMAND HERE\n",
    "# If you have to execute this command through your shell, still paste the command you ran in here.\n",
    "# used the command line to execute the following command: pdftotext -layout  DB_annual_report.pdf DB_annual_report.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Given that the document is extremely long, split the inputs into chunks of 500.000 characters and process them separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_long_text_in_chunks(fp: str, chunk_size: int = 500_000) -> list[str]:\n",
    "    \"\"\"\n",
    "    Loads a text file (located at `fp`) and chunks it into chunks fo at most `chunk_size` characters.\n",
    "    Note that the last chunk might be significantly shorter.\n",
    "    \"\"\"\n",
    "    # Load the text file\n",
    "    #text = ## YOUR CODE\n",
    "    with open(fp, encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "    # Split the text into segments of at most `chunk_size` characters\n",
    "    chunks = [ text[i:i+chunk_size] for i in range(0, len(text), chunk_size) ]\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk size 500000\n",
      "chunk size 500000\n",
      "chunk size 500000\n",
      "chunk size 500000\n",
      "chunk size 500000\n",
      "chunk size 232735\n"
     ]
    }
   ],
   "source": [
    "db_chunks = load_long_text_in_chunks(\"DB_annual_report.txt\") ## YOUR CODE HERE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Print the top 5 occurring `ORG` entities that are not referencing Deutsche Bank itself, both by using spaCy's NER module and the NER function of NLTK.  \n",
    "To exclude \"Deutsche Bank\" entities, filter out all entities that contain both \"deutsche\" and \"bank\" in their name, irrespective of the actual upper-/lowercasing.\n",
    "**Hint:** For more information on how to run NER with NLTK, see [here](https://nanonets.com/blog/named-entity-recognition-with-nltk-and-spacy/#performing-ner-with-nltk-and-spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "org_entities_spacy = []\n",
    "org_entities_nltk = []\n",
    "\n",
    "def is_deutsche_bank_entity(name: str) -> bool:\n",
    "    \"\"\"\n",
    "    Returns True if the entity name contains \"deutsche\" and \"bank\" in some upper-/lowercased version.\n",
    "    This means both \"Deutsche Bank\" and \"deutsche bank's\" should be recognized.\n",
    "    \"\"\"\n",
    "    ## YOUR CODE\n",
    "\n",
    "for chunk in db_chunks:\n",
    "    # Process the chunk with spaCy\n",
    "    doc = ## YOUR CODE\n",
    "\n",
    "    # And also with NLTK\n",
    "    ## YOUR CODE\n",
    "    \n",
    "\n",
    "    # Add all the extracted \"ORG\" entities to `org_entities`, except those referencing Deutsche Bank\n",
    "    org_entities_spacy.extend( ## YOUR CODE\n",
    "    org_entities_nltk.extend( ## YOUR CODE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the top 5 entities by frequency\n",
    "\n",
    "entity_counts_spacy = ## YOUR CODE\n",
    "entity_counts_nltk = ## YOUR CODE\n",
    "\n",
    "print( ## YOUR CODE\n",
    "print( ## YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Compare and analyze the different results between the two methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub Task 3: Co-Occurrence Counts of Entities (5 Points)\n",
    "\n",
    "As is becoming apparent, the *raw* occurrence counts of entities might not be meaningful on its own, especially if we are interested in less frequently occurring entities.\n",
    "\n",
    "Instead, we will \"investigate\" the entities that are most frequently mentioned in association with \"Deutsche Bank\". For this purpose, we will look at the textual co-occurrences of two named entities. The basic idea is that entities that frequently appear together are likely related.\n",
    "\n",
    "1. For each text chunk, extract all mentions of the entity `('Deutsche Bank', 'ORG')`, as well as all `PERSON` entity mentions in the text using spaCy. Store the respective entity name and the text position. Unlike the previous question, you do *not* need to check for different spelllings of the \"Deutsche Bank\" entity.  \n",
    "**Hint:** Entities are represented as a [`Span`](https://spacy.io/api/span) element in spaCy, which has access to text position.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_mentions_with_start_position = []\n",
    "\n",
    "for chunk in db_chunks:\n",
    "    chunk_mentions = []\n",
    "    # Process the doc with spaCy\n",
    "    doc = ## YOUR CODE\n",
    "    \n",
    "    # Extract only entity mentions of \"Deutsche Bank\" (ORG) or any PERSON mention.\n",
    "    # Append each mention, including the text and its starting position, to `chunk_mentions`\n",
    "    \n",
    "    # Append the chunk's entities to the aggregate list\n",
    "    entity_mentions_with_start_position.append(chunk_mentions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Within each chunk, for each mention of `Deutsche Bank`, search for `PERSON` entities that have a starting position within 200 characters before/after the starting position of the `Deutsche Bank` mention. Count for each `PERSON` entity how many times it occurs nearby a mention of `Deutsche Bank`.  \n",
    "Aggregate the co-occurrences across all chunks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_occurrences = []\n",
    "\n",
    "for chunk_mentions in entity_mentions_with_start_position:\n",
    "    # Iterate through the entities. If the entity is a \"Deutsche Bank\" mention, extract nearby\n",
    "    # PERSON references (less than +/- 200 character difference in the starting position)\n",
    "\n",
    "    ## YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3. Return the number of co-occurrences and the name of the top 5 frequently occurring `PERSON` entities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_occurrence_counts = ## YOUR CODE\n",
    "\n",
    "print( ## YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Look back at the results of your previous task. Are the `PERSON` entities returned by your co-occurrence method the same ones that appear most frequently by raw counts?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Neural Models with Huggingface (3 + 5 + 2 = 10 Points)\n",
    "\n",
    "For state-of-the-art performance, most text-related tasks nowadays use some variation of the Transformer architecture. The particular advantage is especiall the readily available weights for models that have been pre-trained on large general-purpose datasets, which reduces the amount of domain-specific labeled training data.\n",
    "\n",
    "In this task, we will explore the [Huggingface](https://hf.co/) ecosystem to see in which way Transformer models can be used.\n",
    "One of the central aspects of the Huggingface platform is the so-called [Model Hub](https://huggingface.co/models), where you can find many different models uploaded by community members for a variety of tasks.\n",
    "\n",
    "Because the neural models are generally very expensive to run, this exercise will be limited to  less data than in previous questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub Task 1: Loading Transformer Models (3 Points)\n",
    "\n",
    "1. Install the `transformers` library and load the model `cardiffnlp/twitter-roberta-base-sentiment-latest` to classify a sequence.\n",
    "2. Report the result of the prediction on the test sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jakob/Dokumente/studium/WahlVL/DataScience/AssigmnentCode/Assigment3/env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'neutral', 'score': 0.780809223651886}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification,pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "\n",
    "prediction = pipeline(\"sentiment-analysis\",model=model,tokenizer=tokenizer)\n",
    "input_text = \"Das ist ein Test.\"\n",
    "prediction(input_text)\n",
    "#prediction = ## YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub Task 2: Using Pipelines (5 Points)\n",
    "\n",
    "The most succinct way of using a Transformer model is the [`transformers.pipeline`](https://huggingface.co/docs/transformers/pipeline_tutorial). You can check out the linked tutorial for more information on the topic, but essentially, `pipeline` provides a light-weight wrapper around a number of different popular NLP tasks\n",
    "\n",
    "1. Instead of manually defining a pipeline, now load a model through a `\"text-classification\"` pipeline. Look up the neural model that is loaded by default, and post the link to its [model card](https://huggingface.co/docs/hub/model-cards) below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Downloading: 100%|██████████| 629/629 [00:00<00:00, 158kB/s]\n",
      "Downloading: 100%|██████████| 268M/268M [00:43<00:00, 6.23MB/s] \n",
      "Downloading: 100%|██████████| 48.0/48.0 [00:00<00:00, 10.3kB/s]\n",
      "Downloading: 100%|██████████| 232k/232k [00:00<00:00, 439kB/s] \n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text-classification\")\n",
    "# link to model card: https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/blob/main/README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Now, instead, load a pipeline for `\"text-classification\"`, but with a custom model and tokenizer. Use the Model Hub platform to find the most popular model for the German language (by number of downloads) and manually specify the usage of another model (and tokenizer) to the pipeline. Re-run the previous example, and report the prediction result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'de', 'score': 0.9929130673408508}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"papluca/xlm-roberta-base-language-detection\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"papluca/xlm-roberta-base-language-detection\")\n",
    "\n",
    "# Instantiate the pipeline with custom components\n",
    "pipe =pipeline(\"text-classification\",model=model,tokenizer=tokenizer)\n",
    "\n",
    "# Output the prediction by your pipe on the test sample.\n",
    "print(pipe(input_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Keeping in line with the previous exercises, let us now try and actually predict something with the model. Re-load a pipeline, this time for Named Entity Recognition, using the default model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"ner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run the pipeline with the text from the Deutsche Bank report from Question 2 and output the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'I-ORG', 'score': 0.9962645, 'index': 1, 'word': 'Deutsche', 'start': 0, 'end': 8}, {'entity': 'I-ORG', 'score': 0.9980811, 'index': 2, 'word': 'Bank', 'start': 9, 'end': 13}, {'entity': 'I-ORG', 'score': 0.9950453, 'index': 7, 'word': 'Deutsche', 'start': 38, 'end': 46}, {'entity': 'I-ORG', 'score': 0.997999, 'index': 8, 'word': 'Bank', 'start': 47, 'end': 51}, {'entity': 'I-ORG', 'score': 0.95706505, 'index': 9, 'word': 'Deutsche', 'start': 105, 'end': 113}, {'entity': 'I-ORG', 'score': 0.9976624, 'index': 10, 'word': 'Bank', 'start': 114, 'end': 118}, {'entity': 'I-ORG', 'score': 0.9963329, 'index': 15, 'word': 'Deutsche', 'start': 142, 'end': 150}, {'entity': 'I-ORG', 'score': 0.9973074, 'index': 16, 'word': 'Bank', 'start': 151, 'end': 155}, {'entity': 'I-ORG', 'score': 0.9989078, 'index': 213, 'word': 'Deutsche', 'start': 2148, 'end': 2156}, {'entity': 'I-ORG', 'score': 0.9987111, 'index': 214, 'word': 'Bank', 'start': 2157, 'end': 2161}]\n",
      "[{'entity': 'I-ORG', 'score': 0.9991985, 'index': 35, 'word': 'Deutsche', 'start': 315, 'end': 323}, {'entity': 'I-ORG', 'score': 0.99907935, 'index': 36, 'word': 'Bank', 'start': 324, 'end': 328}, {'entity': 'I-ORG', 'score': 0.9663349, 'index': 37, 'word': 'Risk', 'start': 364, 'end': 368}, {'entity': 'I-ORG', 'score': 0.97795916, 'index': 38, 'word': 'and', 'start': 369, 'end': 372}, {'entity': 'I-ORG', 'score': 0.9859126, 'index': 39, 'word': 'Capital', 'start': 373, 'end': 380}, {'entity': 'I-ORG', 'score': 0.98171496, 'index': 40, 'word': 'Management', 'start': 381, 'end': 391}, {'entity': 'I-MISC', 'score': 0.4833245, 'index': 54, 'word': 'Internal', 'start': 499, 'end': 507}, {'entity': 'I-MISC', 'score': 0.9374172, 'index': 62, 'word': 'I', 'start': 532, 'end': 533}, {'entity': 'I-MISC', 'score': 0.7550988, 'index': 64, 'word': '##A', 'start': 535, 'end': 536}, {'entity': 'I-MISC', 'score': 0.6605439, 'index': 230, 'word': 'I', 'start': 1437, 'end': 1438}, {'entity': 'I-ORG', 'score': 0.6456954, 'index': 241, 'word': '##V', 'start': 1473, 'end': 1474}, {'entity': 'I-MISC', 'score': 0.83904827, 'index': 318, 'word': 'I', 'start': 1859, 'end': 1860}, {'entity': 'I-MISC', 'score': 0.92789215, 'index': 463, 'word': 'Article', 'start': 2630, 'end': 2637}, {'entity': 'I-MISC', 'score': 0.7347486, 'index': 464, 'word': '150', 'start': 2638, 'end': 2641}, {'entity': 'I-LOC', 'score': 0.5288248, 'index': 476, 'word': 'Republic', 'start': 2696, 'end': 2704}, {'entity': 'I-LOC', 'score': 0.9880382, 'index': 478, 'word': 'Germany', 'start': 2708, 'end': 2715}, {'entity': 'I-MISC', 'score': 0.99861777, 'index': 481, 'word': 'German', 'start': 2726, 'end': 2732}, {'entity': 'I-MISC', 'score': 0.9969207, 'index': 495, 'word': 'European', 'start': 2809, 'end': 2817}, {'entity': 'I-MISC', 'score': 0.8537103, 'index': 497, 'word': 'States', 'start': 2825, 'end': 2831}]\n",
      "[{'entity': 'I-ORG', 'score': 0.9980909, 'index': 96, 'word': 'Deutsche', 'start': 588, 'end': 596}, {'entity': 'I-ORG', 'score': 0.99704665, 'index': 97, 'word': 'Bank', 'start': 597, 'end': 601}, {'entity': 'I-ORG', 'score': 0.77586365, 'index': 171, 'word': 'O', 'start': 1057, 'end': 1058}, {'entity': 'I-ORG', 'score': 0.8566895, 'index': 172, 'word': '##TC', 'start': 1058, 'end': 1060}, {'entity': 'I-ORG', 'score': 0.95937806, 'index': 177, 'word': 'O', 'start': 1087, 'end': 1088}, {'entity': 'I-ORG', 'score': 0.9646256, 'index': 178, 'word': '##TC', 'start': 1088, 'end': 1090}, {'entity': 'I-ORG', 'score': 0.5582554, 'index': 196, 'word': 'CC', 'start': 1175, 'end': 1177}, {'entity': 'I-MISC', 'score': 0.9980102, 'index': 204, 'word': 'Dodd', 'start': 1205, 'end': 1209}, {'entity': 'I-MISC', 'score': 0.9906577, 'index': 205, 'word': '-', 'start': 1209, 'end': 1210}, {'entity': 'I-MISC', 'score': 0.9959675, 'index': 206, 'word': 'Frank', 'start': 1210, 'end': 1215}, {'entity': 'I-MISC', 'score': 0.99768496, 'index': 207, 'word': 'Act', 'start': 1216, 'end': 1219}, {'entity': 'I-ORG', 'score': 0.8846242, 'index': 217, 'word': 'O', 'start': 1278, 'end': 1279}, {'entity': 'I-ORG', 'score': 0.92056274, 'index': 218, 'word': '##TC', 'start': 1279, 'end': 1281}, {'entity': 'I-ORG', 'score': 0.8540621, 'index': 232, 'word': 'O', 'start': 1379, 'end': 1380}, {'entity': 'I-ORG', 'score': 0.8311037, 'index': 233, 'word': '##TC', 'start': 1380, 'end': 1382}, {'entity': 'I-MISC', 'score': 0.9969458, 'index': 278, 'word': 'Dodd', 'start': 1639, 'end': 1643}, {'entity': 'I-MISC', 'score': 0.9883315, 'index': 279, 'word': '-', 'start': 1643, 'end': 1644}, {'entity': 'I-MISC', 'score': 0.99609417, 'index': 280, 'word': 'Frank', 'start': 1644, 'end': 1649}, {'entity': 'I-MISC', 'score': 0.9970499, 'index': 281, 'word': 'Act', 'start': 1650, 'end': 1653}, {'entity': 'I-ORG', 'score': 0.97017586, 'index': 284, 'word': 'CF', 'start': 1666, 'end': 1668}, {'entity': 'I-ORG', 'score': 0.982178, 'index': 285, 'word': '##TC', 'start': 1668, 'end': 1670}, {'entity': 'I-ORG', 'score': 0.91761523, 'index': 288, 'word': 'O', 'start': 1685, 'end': 1686}, {'entity': 'I-ORG', 'score': 0.8996266, 'index': 289, 'word': '##TC', 'start': 1686, 'end': 1688}, {'entity': 'I-LOC', 'score': 0.99926883, 'index': 293, 'word': 'United', 'start': 1705, 'end': 1711}, {'entity': 'I-LOC', 'score': 0.99879813, 'index': 294, 'word': 'States', 'start': 1712, 'end': 1718}, {'entity': 'I-ORG', 'score': 0.7466336, 'index': 298, 'word': 'O', 'start': 1744, 'end': 1745}, {'entity': 'I-ORG', 'score': 0.8212171, 'index': 299, 'word': '##TC', 'start': 1745, 'end': 1747}, {'entity': 'I-LOC', 'score': 0.99880314, 'index': 327, 'word': 'US', 'start': 1910, 'end': 1912}, {'entity': 'I-MISC', 'score': 0.98103964, 'index': 334, 'word': 'European', 'start': 1944, 'end': 1952}, {'entity': 'I-MISC', 'score': 0.99541277, 'index': 335, 'word': 'Regulation', 'start': 1953, 'end': 1963}, {'entity': 'I-ORG', 'score': 0.9891811, 'index': 337, 'word': 'EU', 'start': 1965, 'end': 1967}, {'entity': 'I-MISC', 'score': 0.5351326, 'index': 339, 'word': 'No', 'start': 1969, 'end': 1971}, {'entity': 'I-ORG', 'score': 0.75592685, 'index': 345, 'word': 'O', 'start': 1984, 'end': 1985}, {'entity': 'I-ORG', 'score': 0.67505985, 'index': 346, 'word': '##TC', 'start': 1985, 'end': 1987}, {'entity': 'I-MISC', 'score': 0.4900587, 'index': 347, 'word': 'Der', 'start': 1988, 'end': 1991}, {'entity': 'I-ORG', 'score': 0.4201944, 'index': 356, 'word': 'Trade', 'start': 2028, 'end': 2033}, {'entity': 'I-MISC', 'score': 0.5669581, 'index': 357, 'word': 'Rep', 'start': 2034, 'end': 2037}, {'entity': 'I-MISC', 'score': 0.4812986, 'index': 363, 'word': 'EMI', 'start': 2049, 'end': 2052}, {'entity': 'I-ORG', 'score': 0.8307449, 'index': 382, 'word': 'O', 'start': 2132, 'end': 2133}, {'entity': 'I-ORG', 'score': 0.83923393, 'index': 383, 'word': '##TC', 'start': 2133, 'end': 2135}, {'entity': 'I-ORG', 'score': 0.9783972, 'index': 392, 'word': '##TC', 'start': 2178, 'end': 2180}, {'entity': 'I-MISC', 'score': 0.4119175, 'index': 401, 'word': '##da', 'start': 2225, 'end': 2227}, {'entity': 'I-ORG', 'score': 0.98764604, 'index': 408, 'word': '##TC', 'start': 2266, 'end': 2268}, {'entity': 'I-ORG', 'score': 0.9640999, 'index': 413, 'word': 'EU', 'start': 2301, 'end': 2303}, {'entity': 'I-ORG', 'score': 0.99396306, 'index': 427, 'word': '##TC', 'start': 2364, 'end': 2366}, {'entity': 'I-ORG', 'score': 0.9517455, 'index': 432, 'word': 'EU', 'start': 2398, 'end': 2400}, {'entity': 'I-ORG', 'score': 0.96632963, 'index': 438, 'word': 'Deutsche', 'start': 2427, 'end': 2435}, {'entity': 'I-ORG', 'score': 0.88453954, 'index': 439, 'word': 'Bank', 'start': 2436, 'end': 2440}, {'entity': 'I-ORG', 'score': 0.93869084, 'index': 451, 'word': 'EU', 'start': 2510, 'end': 2512}, {'entity': 'I-ORG', 'score': 0.945693, 'index': 476, 'word': 'CF', 'start': 2646, 'end': 2648}, {'entity': 'I-ORG', 'score': 0.98934585, 'index': 477, 'word': '##TC', 'start': 2648, 'end': 2650}, {'entity': 'I-MISC', 'score': 0.8643783, 'index': 488, 'word': 'Dodd', 'start': 2721, 'end': 2725}, {'entity': 'I-MISC', 'score': 0.9244941, 'index': 490, 'word': 'Frank', 'start': 2726, 'end': 2731}, {'entity': 'I-MISC', 'score': 0.9273642, 'index': 491, 'word': 'Act', 'start': 2732, 'end': 2735}, {'entity': 'I-ORG', 'score': 0.9894723, 'index': 501, 'word': 'CF', 'start': 2775, 'end': 2777}, {'entity': 'I-ORG', 'score': 0.97903305, 'index': 502, 'word': '##TC', 'start': 2777, 'end': 2779}]\n",
      "[{'entity': 'I-ORG', 'score': 0.93696076, 'index': 23, 'word': 'Corporate', 'start': 294, 'end': 303}, {'entity': 'I-ORG', 'score': 0.9843716, 'index': 24, 'word': 'Investment', 'start': 312, 'end': 322}, {'entity': 'I-ORG', 'score': 0.9882301, 'index': 25, 'word': 'Private', 'start': 333, 'end': 340}, {'entity': 'I-ORG', 'score': 0.9932326, 'index': 26, 'word': 'As', 'start': 352, 'end': 354}, {'entity': 'I-ORG', 'score': 0.96516776, 'index': 27, 'word': '##set', 'start': 354, 'end': 357}, {'entity': 'I-ORG', 'score': 0.98879725, 'index': 28, 'word': 'Capital', 'start': 369, 'end': 376}, {'entity': 'I-ORG', 'score': 0.9669598, 'index': 29, 'word': 'Corporate', 'start': 379, 'end': 388}, {'entity': 'I-ORG', 'score': 0.5817151, 'index': 30, 'word': '&', 'start': 389, 'end': 390}, {'entity': 'I-ORG', 'score': 0.9965121, 'index': 37, 'word': 'Bank', 'start': 447, 'end': 451}, {'entity': 'I-ORG', 'score': 0.9990044, 'index': 38, 'word': 'Bank', 'start': 467, 'end': 471}, {'entity': 'I-ORG', 'score': 0.99851674, 'index': 39, 'word': 'Bank', 'start': 484, 'end': 488}, {'entity': 'I-ORG', 'score': 0.99838555, 'index': 40, 'word': 'Management', 'start': 496, 'end': 506}, {'entity': 'I-ORG', 'score': 0.9917092, 'index': 41, 'word': 'Release', 'start': 513, 'end': 520}, {'entity': 'I-ORG', 'score': 0.99273634, 'index': 42, 'word': 'Unit', 'start': 521, 'end': 525}, {'entity': 'I-ORG', 'score': 0.78978854, 'index': 338, 'word': 'Corporate', 'start': 3301, 'end': 3310}, {'entity': 'I-ORG', 'score': 0.92526376, 'index': 339, 'word': 'Investment', 'start': 3319, 'end': 3329}, {'entity': 'I-ORG', 'score': 0.9830541, 'index': 340, 'word': 'Private', 'start': 3340, 'end': 3347}, {'entity': 'I-ORG', 'score': 0.99288976, 'index': 341, 'word': 'As', 'start': 3359, 'end': 3361}, {'entity': 'I-ORG', 'score': 0.9638924, 'index': 342, 'word': '##set', 'start': 3361, 'end': 3364}, {'entity': 'I-ORG', 'score': 0.9914608, 'index': 343, 'word': 'Capital', 'start': 3376, 'end': 3383}, {'entity': 'I-ORG', 'score': 0.9725264, 'index': 344, 'word': 'Corporate', 'start': 3386, 'end': 3395}, {'entity': 'I-ORG', 'score': 0.8655904, 'index': 345, 'word': '&', 'start': 3396, 'end': 3397}, {'entity': 'I-ORG', 'score': 0.75638366, 'index': 346, 'word': 'Total', 'start': 3411, 'end': 3416}, {'entity': 'I-ORG', 'score': 0.992539, 'index': 352, 'word': 'Bank', 'start': 3454, 'end': 3458}, {'entity': 'I-ORG', 'score': 0.9976987, 'index': 353, 'word': 'Bank', 'start': 3474, 'end': 3478}, {'entity': 'I-ORG', 'score': 0.99374086, 'index': 354, 'word': 'Bank', 'start': 3491, 'end': 3495}, {'entity': 'I-ORG', 'score': 0.9927492, 'index': 355, 'word': 'Management', 'start': 3503, 'end': 3513}, {'entity': 'I-ORG', 'score': 0.9790674, 'index': 356, 'word': 'Release', 'start': 3520, 'end': 3527}, {'entity': 'I-ORG', 'score': 0.9873105, 'index': 357, 'word': 'Unit', 'start': 3528, 'end': 3532}, {'entity': 'I-ORG', 'score': 0.6209793, 'index': 397, 'word': 'Commission', 'start': 3922, 'end': 3932}, {'entity': 'I-ORG', 'score': 0.7085959, 'index': 447, 'word': 'Commission', 'start': 4402, 'end': 4412}, {'entity': 'I-ORG', 'score': 0.7145014, 'index': 466, 'word': 'Commission', 'start': 4571, 'end': 4581}, {'entity': 'I-ORG', 'score': 0.7282201, 'index': 483, 'word': 'Commission', 'start': 4742, 'end': 4752}, {'entity': 'I-ORG', 'score': 0.7130353, 'index': 498, 'word': 'Commission', 'start': 4932, 'end': 4942}]\n",
      "[{'entity': 'I-ORG', 'score': 0.97986126, 'index': 17, 'word': 'Group', 'start': 91, 'end': 96}, {'entity': 'I-ORG', 'score': 0.96067715, 'index': 72, 'word': 'Group', 'start': 422, 'end': 427}, {'entity': 'I-ORG', 'score': 0.97682685, 'index': 140, 'word': 'Group', 'start': 814, 'end': 819}, {'entity': 'I-ORG', 'score': 0.9509856, 'index': 177, 'word': 'Group', 'start': 1015, 'end': 1020}, {'entity': 'I-ORG', 'score': 0.9486346, 'index': 222, 'word': 'Group', 'start': 1251, 'end': 1256}, {'entity': 'I-ORG', 'score': 0.9262644, 'index': 243, 'word': 'Group', 'start': 1364, 'end': 1369}, {'entity': 'I-ORG', 'score': 0.98075014, 'index': 287, 'word': 'Group', 'start': 1642, 'end': 1647}, {'entity': 'I-ORG', 'score': 0.9379193, 'index': 358, 'word': 'Group', 'start': 2002, 'end': 2007}]\n",
      "[{'entity': 'I-PER', 'score': 0.99969804, 'index': 10, 'word': 'Kimberly', 'start': 97, 'end': 105}, {'entity': 'I-PER', 'score': 0.99967766, 'index': 11, 'word': 'Hammond', 'start': 106, 'end': 113}, {'entity': 'I-PER', 'score': 0.9984282, 'index': 12, 'word': '##s', 'start': 113, 'end': 114}, {'entity': 'I-PER', 'score': 0.9997527, 'index': 26, 'word': 'Marcus', 'start': 270, 'end': 276}, {'entity': 'I-PER', 'score': 0.99979454, 'index': 27, 'word': 'Sc', 'start': 277, 'end': 279}, {'entity': 'I-PER', 'score': 0.9954266, 'index': 28, 'word': '##hen', 'start': 279, 'end': 282}, {'entity': 'I-PER', 'score': 0.9976513, 'index': 29, 'word': '##ck', 'start': 282, 'end': 284}, {'entity': 'I-PER', 'score': 0.99974257, 'index': 41, 'word': 'John', 'start': 435, 'end': 439}, {'entity': 'I-PER', 'score': 0.9996433, 'index': 42, 'word': 'Cry', 'start': 440, 'end': 443}, {'entity': 'I-PER', 'score': 0.9995055, 'index': 43, 'word': '##an', 'start': 443, 'end': 445}, {'entity': 'I-PER', 'score': 0.9997477, 'index': 55, 'word': 'Hermann', 'start': 604, 'end': 611}, {'entity': 'I-PER', 'score': 0.9984042, 'index': 56, 'word': '-', 'start': 611, 'end': 612}, {'entity': 'I-PER', 'score': 0.99975306, 'index': 57, 'word': 'Josef', 'start': 612, 'end': 617}, {'entity': 'I-PER', 'score': 0.9998142, 'index': 58, 'word': 'Lambert', 'start': 618, 'end': 625}, {'entity': 'I-PER', 'score': 0.9991196, 'index': 59, 'word': '##i', 'start': 625, 'end': 626}, {'entity': 'I-PER', 'score': 0.99971515, 'index': 78, 'word': 'Josef', 'start': 774, 'end': 779}, {'entity': 'I-PER', 'score': 0.99978334, 'index': 79, 'word': 'A', 'start': 780, 'end': 781}, {'entity': 'I-PER', 'score': 0.99857724, 'index': 80, 'word': '##cker', 'start': 781, 'end': 785}, {'entity': 'I-PER', 'score': 0.9985757, 'index': 81, 'word': '##mann', 'start': 785, 'end': 789}, {'entity': 'I-ORG', 'score': 0.74444157, 'index': 96, 'word': 'Super', 'start': 943, 'end': 948}, {'entity': 'I-ORG', 'score': 0.72856253, 'index': 97, 'word': '##visor', 'start': 948, 'end': 953}, {'entity': 'I-ORG', 'score': 0.72034353, 'index': 98, 'word': '##y', 'start': 953, 'end': 954}, {'entity': 'I-ORG', 'score': 0.9488236, 'index': 99, 'word': 'Board', 'start': 955, 'end': 960}, {'entity': 'I-ORG', 'score': 0.48690394, 'index': 110, 'word': 'Super', 'start': 997, 'end': 1002}, {'entity': 'I-ORG', 'score': 0.9129999, 'index': 113, 'word': 'Board', 'start': 1009, 'end': 1014}, {'entity': 'I-PER', 'score': 0.9997571, 'index': 117, 'word': 'Paul', 'start': 1030, 'end': 1034}, {'entity': 'I-PER', 'score': 0.9997098, 'index': 118, 'word': 'A', 'start': 1035, 'end': 1036}, {'entity': 'I-PER', 'score': 0.9983911, 'index': 119, 'word': '##ch', 'start': 1036, 'end': 1038}, {'entity': 'I-PER', 'score': 0.9492673, 'index': 120, 'word': '##le', 'start': 1038, 'end': 1040}, {'entity': 'I-PER', 'score': 0.9448794, 'index': 121, 'word': '##it', 'start': 1040, 'end': 1042}, {'entity': 'I-PER', 'score': 0.9935033, 'index': 122, 'word': '##ner', 'start': 1042, 'end': 1045}, {'entity': 'I-PER', 'score': 0.9997868, 'index': 127, 'word': 'Det', 'start': 1195, 'end': 1198}, {'entity': 'I-PER', 'score': 0.99903107, 'index': 128, 'word': '##le', 'start': 1198, 'end': 1200}, {'entity': 'I-PER', 'score': 0.9996772, 'index': 129, 'word': '##f', 'start': 1200, 'end': 1201}, {'entity': 'I-PER', 'score': 0.9996277, 'index': 130, 'word': 'Pol', 'start': 1202, 'end': 1205}, {'entity': 'I-PER', 'score': 0.99577737, 'index': 131, 'word': '##as', 'start': 1205, 'end': 1207}, {'entity': 'I-PER', 'score': 0.98088765, 'index': 132, 'word': '##che', 'start': 1207, 'end': 1210}, {'entity': 'I-PER', 'score': 0.99384624, 'index': 133, 'word': '##k', 'start': 1210, 'end': 1211}, {'entity': 'I-PER', 'score': 0.99972194, 'index': 137, 'word': 'Ludwig', 'start': 1364, 'end': 1370}, {'entity': 'I-PER', 'score': 0.9998357, 'index': 138, 'word': 'B', 'start': 1371, 'end': 1372}, {'entity': 'I-PER', 'score': 0.99880254, 'index': 139, 'word': '##lo', 'start': 1372, 'end': 1374}, {'entity': 'I-PER', 'score': 0.9990109, 'index': 140, 'word': '##meyer', 'start': 1374, 'end': 1379}, {'entity': 'I-PER', 'score': 0.7606355, 'index': 141, 'word': '-', 'start': 1379, 'end': 1380}, {'entity': 'I-PER', 'score': 0.99974746, 'index': 142, 'word': 'Bart', 'start': 1380, 'end': 1384}, {'entity': 'I-PER', 'score': 0.9992693, 'index': 143, 'word': '##enstein', 'start': 1384, 'end': 1391}, {'entity': 'I-PER', 'score': 0.99969065, 'index': 147, 'word': 'May', 'start': 1533, 'end': 1536}, {'entity': 'I-PER', 'score': 0.99960965, 'index': 148, 'word': '##ree', 'start': 1536, 'end': 1539}, {'entity': 'I-PER', 'score': 0.9998141, 'index': 149, 'word': 'Clark', 'start': 1540, 'end': 1545}, {'entity': 'I-PER', 'score': 0.9997595, 'index': 153, 'word': 'Jan', 'start': 1702, 'end': 1705}, {'entity': 'I-PER', 'score': 0.9997147, 'index': 154, 'word': 'Du', 'start': 1706, 'end': 1708}, {'entity': 'I-PER', 'score': 0.9927745, 'index': 155, 'word': '##sche', 'start': 1708, 'end': 1712}, {'entity': 'I-PER', 'score': 0.99214363, 'index': 156, 'word': '##ck', 'start': 1712, 'end': 1714}, {'entity': 'I-PER', 'score': 0.99978036, 'index': 163, 'word': 'Gerhard', 'start': 1875, 'end': 1882}, {'entity': 'I-PER', 'score': 0.9997687, 'index': 164, 'word': 'E', 'start': 1883, 'end': 1884}, {'entity': 'I-PER', 'score': 0.99886537, 'index': 165, 'word': '##sche', 'start': 1884, 'end': 1888}, {'entity': 'I-PER', 'score': 0.98821217, 'index': 166, 'word': '##l', 'start': 1888, 'end': 1889}, {'entity': 'I-PER', 'score': 0.99930274, 'index': 167, 'word': '##beck', 'start': 1889, 'end': 1893}, {'entity': 'I-PER', 'score': 0.9997961, 'index': 171, 'word': 'Sigma', 'start': 2040, 'end': 2045}, {'entity': 'I-PER', 'score': 0.9997539, 'index': 172, 'word': '##r', 'start': 2045, 'end': 2046}, {'entity': 'I-PER', 'score': 0.9998419, 'index': 173, 'word': 'Gabriel', 'start': 2047, 'end': 2054}, {'entity': 'I-PER', 'score': 0.99977106, 'index': 185, 'word': 'Tim', 'start': 2209, 'end': 2212}, {'entity': 'I-PER', 'score': 0.9997162, 'index': 186, 'word': '##o', 'start': 2212, 'end': 2213}, {'entity': 'I-PER', 'score': 0.99978596, 'index': 187, 'word': 'He', 'start': 2214, 'end': 2216}, {'entity': 'I-PER', 'score': 0.99814796, 'index': 188, 'word': '##ider', 'start': 2216, 'end': 2220}, {'entity': 'I-PER', 'score': 0.9997197, 'index': 193, 'word': 'Martina', 'start': 2378, 'end': 2385}, {'entity': 'I-PER', 'score': 0.99984694, 'index': 194, 'word': 'K', 'start': 2386, 'end': 2387}, {'entity': 'I-PER', 'score': 0.9996933, 'index': 195, 'word': '##lee', 'start': 2387, 'end': 2390}, {'entity': 'I-PER', 'score': 0.99972993, 'index': 199, 'word': 'Henri', 'start': 2547, 'end': 2552}, {'entity': 'I-PER', 'score': 0.999736, 'index': 200, 'word': '##ette', 'start': 2552, 'end': 2556}, {'entity': 'I-PER', 'score': 0.99973434, 'index': 201, 'word': 'Mark', 'start': 2557, 'end': 2561}, {'entity': 'I-PER', 'score': 0.9998042, 'index': 205, 'word': 'Gabriel', 'start': 2716, 'end': 2723}, {'entity': 'I-PER', 'score': 0.99966025, 'index': 206, 'word': '##e', 'start': 2723, 'end': 2724}, {'entity': 'I-PER', 'score': 0.99983597, 'index': 207, 'word': 'P', 'start': 2725, 'end': 2726}, {'entity': 'I-PER', 'score': 0.99809617, 'index': 208, 'word': '##lat', 'start': 2726, 'end': 2729}, {'entity': 'I-PER', 'score': 0.9987527, 'index': 209, 'word': '##scher', 'start': 2729, 'end': 2734}, {'entity': 'I-PER', 'score': 0.99980587, 'index': 213, 'word': 'Bern', 'start': 2885, 'end': 2889}, {'entity': 'I-PER', 'score': 0.9997409, 'index': 214, 'word': '##d', 'start': 2889, 'end': 2890}, {'entity': 'I-PER', 'score': 0.99984276, 'index': 215, 'word': 'Rose', 'start': 2891, 'end': 2895}, {'entity': 'I-PER', 'score': 0.9996371, 'index': 219, 'word': 'John', 'start': 3054, 'end': 3058}, {'entity': 'I-PER', 'score': 0.99971336, 'index': 220, 'word': 'Alexander', 'start': 3059, 'end': 3068}, {'entity': 'I-PER', 'score': 0.99840003, 'index': 221, 'word': 'Thai', 'start': 3069, 'end': 3073}, {'entity': 'I-PER', 'score': 0.97865546, 'index': 222, 'word': '##n', 'start': 3073, 'end': 3074}, {'entity': 'I-PER', 'score': 0.99956363, 'index': 226, 'word': 'Michele', 'start': 3223, 'end': 3230}, {'entity': 'I-PER', 'score': 0.99972445, 'index': 227, 'word': 'T', 'start': 3231, 'end': 3232}, {'entity': 'I-PER', 'score': 0.9987419, 'index': 228, 'word': '##rog', 'start': 3232, 'end': 3235}, {'entity': 'I-PER', 'score': 0.9975713, 'index': 229, 'word': '##ni', 'start': 3235, 'end': 3237}, {'entity': 'I-PER', 'score': 0.9997038, 'index': 236, 'word': 'Da', 'start': 3396, 'end': 3398}, {'entity': 'I-PER', 'score': 0.999703, 'index': 237, 'word': '##gma', 'start': 3398, 'end': 3401}, {'entity': 'I-PER', 'score': 0.9996828, 'index': 238, 'word': '##r', 'start': 3401, 'end': 3402}, {'entity': 'I-PER', 'score': 0.99921477, 'index': 239, 'word': 'Val', 'start': 3403, 'end': 3406}, {'entity': 'I-PER', 'score': 0.98786587, 'index': 240, 'word': '##c', 'start': 3406, 'end': 3407}, {'entity': 'I-PER', 'score': 0.98870474, 'index': 241, 'word': '##á', 'start': 3407, 'end': 3408}, {'entity': 'I-PER', 'score': 0.9846541, 'index': 242, 'word': '##rc', 'start': 3408, 'end': 3410}, {'entity': 'I-PER', 'score': 0.99708986, 'index': 243, 'word': '##el', 'start': 3410, 'end': 3412}, {'entity': 'I-PER', 'score': 0.99975187, 'index': 247, 'word': 'Stefan', 'start': 3561, 'end': 3567}, {'entity': 'I-PER', 'score': 0.9997811, 'index': 248, 'word': 'V', 'start': 3568, 'end': 3569}, {'entity': 'I-PER', 'score': 0.9952224, 'index': 249, 'word': '##ier', 'start': 3569, 'end': 3572}, {'entity': 'I-PER', 'score': 0.9971872, 'index': 250, 'word': '##tel', 'start': 3572, 'end': 3575}, {'entity': 'I-PER', 'score': 0.99977106, 'index': 267, 'word': 'Theodor', 'start': 3734, 'end': 3741}, {'entity': 'I-PER', 'score': 0.9997781, 'index': 268, 'word': 'Wei', 'start': 3742, 'end': 3745}, {'entity': 'I-PER', 'score': 0.9988537, 'index': 269, 'word': '##mer', 'start': 3745, 'end': 3748}, {'entity': 'I-PER', 'score': 0.9997712, 'index': 281, 'word': 'Frank', 'start': 3899, 'end': 3904}, {'entity': 'I-PER', 'score': 0.999782, 'index': 282, 'word': 'We', 'start': 3905, 'end': 3907}, {'entity': 'I-PER', 'score': 0.9989518, 'index': 283, 'word': '##rne', 'start': 3907, 'end': 3910}, {'entity': 'I-PER', 'score': 0.99792755, 'index': 284, 'word': '##ke', 'start': 3910, 'end': 3912}, {'entity': 'I-PER', 'score': 0.9998216, 'index': 303, 'word': 'Nor', 'start': 4078, 'end': 4081}, {'entity': 'I-PER', 'score': 0.9997602, 'index': 304, 'word': '##bert', 'start': 4081, 'end': 4085}, {'entity': 'I-PER', 'score': 0.99977607, 'index': 305, 'word': 'Win', 'start': 4086, 'end': 4089}, {'entity': 'I-PER', 'score': 0.99718946, 'index': 306, 'word': '##kel', 'start': 4089, 'end': 4092}, {'entity': 'I-PER', 'score': 0.9961665, 'index': 307, 'word': '##jo', 'start': 4092, 'end': 4094}, {'entity': 'I-PER', 'score': 0.9746498, 'index': 308, 'word': '##han', 'start': 4094, 'end': 4097}, {'entity': 'I-PER', 'score': 0.9862118, 'index': 309, 'word': '##n', 'start': 4097, 'end': 4098}, {'entity': 'I-PER', 'score': 0.99975973, 'index': 314, 'word': 'Frank', 'start': 4237, 'end': 4242}, {'entity': 'I-PER', 'score': 0.99976104, 'index': 315, 'word': 'W', 'start': 4243, 'end': 4244}, {'entity': 'I-PER', 'score': 0.9954887, 'index': 316, 'word': '##itte', 'start': 4244, 'end': 4248}, {'entity': 'I-PER', 'score': 0.9983631, 'index': 317, 'word': '##r', 'start': 4248, 'end': 4249}, {'entity': 'I-ORG', 'score': 0.69710255, 'index': 336, 'word': 'Super', 'start': 4428, 'end': 4433}, {'entity': 'I-ORG', 'score': 0.97304845, 'index': 339, 'word': 'Board', 'start': 4440, 'end': 4445}, {'entity': 'I-PER', 'score': 0.9997521, 'index': 340, 'word': 'Frank', 'start': 4449, 'end': 4454}, {'entity': 'I-PER', 'score': 0.99963784, 'index': 341, 'word': 'B', 'start': 4455, 'end': 4456}, {'entity': 'I-PER', 'score': 0.95489454, 'index': 342, 'word': '##sir', 'start': 4456, 'end': 4459}, {'entity': 'I-PER', 'score': 0.9934023, 'index': 343, 'word': '##ske', 'start': 4459, 'end': 4462}, {'entity': 'I-PER', 'score': 0.9997689, 'index': 358, 'word': 'G', 'start': 4620, 'end': 4621}, {'entity': 'I-PER', 'score': 0.9996431, 'index': 359, 'word': '##erd', 'start': 4621, 'end': 4624}, {'entity': 'I-PER', 'score': 0.9997907, 'index': 360, 'word': 'Alexander', 'start': 4625, 'end': 4634}, {'entity': 'I-PER', 'score': 0.99975437, 'index': 361, 'word': 'Sc', 'start': 4635, 'end': 4637}, {'entity': 'I-PER', 'score': 0.98956966, 'index': 362, 'word': '##h', 'start': 4637, 'end': 4638}, {'entity': 'I-PER', 'score': 0.9739182, 'index': 363, 'word': '##ü', 'start': 4638, 'end': 4639}, {'entity': 'I-PER', 'score': 0.99652314, 'index': 364, 'word': '##tz', 'start': 4639, 'end': 4641}, {'entity': 'I-PER', 'score': 0.99976355, 'index': 379, 'word': 'Stephan', 'start': 4791, 'end': 4798}, {'entity': 'I-PER', 'score': 0.9995894, 'index': 380, 'word': 'S', 'start': 4799, 'end': 4800}, {'entity': 'I-PER', 'score': 0.9981674, 'index': 381, 'word': '##zuka', 'start': 4800, 'end': 4804}, {'entity': 'I-PER', 'score': 0.9488637, 'index': 382, 'word': '##ls', 'start': 4804, 'end': 4806}, {'entity': 'I-PER', 'score': 0.93985116, 'index': 383, 'word': '##ki', 'start': 4806, 'end': 4808}, {'entity': 'I-ORG', 'score': 0.7084024, 'index': 396, 'word': 'M', 'start': 4955, 'end': 4956}, {'entity': 'I-PER', 'score': 0.95618325, 'index': 397, 'word': 'Katherine', 'start': 4960, 'end': 4969}, {'entity': 'I-ORG', 'score': 0.9931666, 'index': 398, 'word': 'Garrett', 'start': 4970, 'end': 4977}, {'entity': 'I-ORG', 'score': 0.93723893, 'index': 413, 'word': 'M', 'start': 5124, 'end': 5125}, {'entity': 'I-ORG', 'score': 0.9820885, 'index': 443, 'word': 'Deutsche', 'start': 5454, 'end': 5462}, {'entity': 'I-ORG', 'score': 0.98014694, 'index': 444, 'word': 'Bank', 'start': 5463, 'end': 5467}, {'entity': 'I-ORG', 'score': 0.9901002, 'index': 462, 'word': 'Deutsche', 'start': 5586, 'end': 5594}, {'entity': 'I-ORG', 'score': 0.9798146, 'index': 463, 'word': 'Bank', 'start': 5595, 'end': 5599}, {'entity': 'I-ORG', 'score': 0.5211622, 'index': 464, 'word': 'A', 'start': 5600, 'end': 5601}, {'entity': 'I-ORG', 'score': 0.92740244, 'index': 466, 'word': '##ien', 'start': 5603, 'end': 5606}, {'entity': 'I-ORG', 'score': 0.9407331, 'index': 468, 'word': '##ell', 'start': 5609, 'end': 5612}, {'entity': 'I-ORG', 'score': 0.93277407, 'index': 470, 'word': '##aft', 'start': 5615, 'end': 5618}, {'entity': 'I-ORG', 'score': 0.846644, 'index': 472, 'word': 'Frankfurt', 'start': 5620, 'end': 5629}, {'entity': 'I-ORG', 'score': 0.55606246, 'index': 474, 'word': 'Main', 'start': 5633, 'end': 5637}, {'entity': 'I-ORG', 'score': 0.86749977, 'index': 482, 'word': '##mu', 'start': 5670, 'end': 5672}, {'entity': 'I-ORG', 'score': 0.9204057, 'index': 483, 'word': '##ner', 'start': 5672, 'end': 5675}, {'entity': 'I-PER', 'score': 0.9548828, 'index': 487, 'word': 'Deutsche', 'start': 5691, 'end': 5699}, {'entity': 'I-ORG', 'score': 0.99114096, 'index': 488, 'word': 'Bank', 'start': 5700, 'end': 5704}, {'entity': 'I-ORG', 'score': 0.6746267, 'index': 491, 'word': '##ien', 'start': 5708, 'end': 5711}, {'entity': 'I-ORG', 'score': 0.5384267, 'index': 492, 'word': '##ges', 'start': 5711, 'end': 5714}, {'entity': 'I-ORG', 'score': 0.6713599, 'index': 493, 'word': '##ell', 'start': 5714, 'end': 5717}, {'entity': 'I-ORG', 'score': 0.9190146, 'index': 495, 'word': '##aft', 'start': 5720, 'end': 5723}, {'entity': 'I-LOC', 'score': 0.49630567, 'index': 497, 'word': 'Frankfurt', 'start': 5725, 'end': 5734}, {'entity': 'I-ORG', 'score': 0.6977007, 'index': 499, 'word': 'Main', 'start': 5738, 'end': 5742}, {'entity': 'I-ORG', 'score': 0.58336115, 'index': 505, 'word': 'Se', 'start': 5768, 'end': 5770}]\n"
     ]
    }
   ],
   "source": [
    "db_chunks = load_long_text_in_chunks(\"DB_annual_report.txt\") ## YOUR CODE HERE)\n",
    "for chunk in db_chunks:\n",
    "    print(pipe(chunk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Look at the results. Something looks strange here; why is it not working properly? Elaborate your answer."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "german compunds like deutsche bank or Frankfurt am Main are splitted into several token and each token is then classified as an Named Entity. \n",
    "One reason could be that the used pipeline from the transformers library split these compounds into several tokens which are then passed indiviually to the model.\n",
    "This would justify our observation that the phrase  could explain why in a sentence like \"Headquartered in Frankfurt am Main, Germany, Deutsche Bank is the largest bank in Germany and one of the largest financial instutions [...]\" taken from the DB annual report, the city Frankfurt am Main is misclassified as three indiviual International Organisations whereas the same sentence tested on the website of the model ( https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english) leads to the correct classification o f Frankfurt am Main as an international Location. \n",
    "\n",
    "Another possible reason is,that given that we split the annual report in chunks and run the NER on the chunks, it could happen that some compounds are splitted into several chunks e.g one chunk contains the word \"Frankfurt\" and another chunk contains the words \"am Main\", although this not likely to happen very often since the text in only split in six chunks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub Task 3: Using Datasets through Huggingface (2 Points)\n",
    "\n",
    "Instead of using the `transformers` library for model training and inference, it is also possible to use other libraries by Huggingface without neural models.\n",
    "In particular, the `datasets` library provides a centralized and streamlined way of accessing a variety of different datasets.\n",
    "\n",
    "1. Using the `datasets` library, load the `imdb` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/jakob/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n",
      "100%|██████████| 3/3 [00:00<00:00, 396.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    unsupervised: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset,get_dataset_split_names\n",
    "\n",
    "dataset = load_dataset(\"imdb\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Report the mean length of `text` column for the training, validation and test split, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1325.06964\n",
      "1293.7924\n",
      "1329.9025\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE\n",
    "training_data = dataset[\"train\"][\"text\"]\n",
    "mean_training_data = sum(len(text)for text in training_data)/ len(training_data)\n",
    "print(mean_training_data)\n",
    "test_data = dataset[\"test\"][\"text\"]\n",
    "mean_test_data = sum(len(text)for text in test_data)/ len(test_data)\n",
    "print(mean_test_data)\n",
    "validation_data = dataset[\"unsupervised\"][\"text\"]\n",
    "mean_validation_data = sum(len(text)for text in validation_data)/ len(validation_data)\n",
    "print(mean_validation_data)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LSTM_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "ee137d90ddcc716da987c7483995b8ffdfcddb1aae4b3e859fde0379c429a4c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
