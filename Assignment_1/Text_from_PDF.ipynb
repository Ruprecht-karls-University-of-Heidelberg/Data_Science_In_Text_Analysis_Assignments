{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ac05fc1",
   "metadata": {},
   "source": [
    "# Problem 1-3 Information Extraction from PDF Documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d97541be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76040c93",
   "metadata": {},
   "source": [
    "## 1. Different methods for string extration from PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd0fcbf",
   "metadata": {},
   "source": [
    "### Try two different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23746ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "def conversion_with_pypdf2(pdf_file):\n",
    "    \"\"\"Return a string with the text extracted from the given pdf_file using PyPDF2.\"\"\"\n",
    "    # copied from https://stackoverflow.com/questions/23821204/read-pdf-in-python-and-convert-to-text-in-pdf, first answer\n",
    "    pypdf2_reader = PdfReader(pdf_file)\n",
    "    text = \"\"\n",
    "    for page in pypdf2_reader.pages:\n",
    "        text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "import pypdfium2 as pdfium\n",
    "def conversion_with_pypdfium2(pdf_file):\n",
    "    \"\"\"Return a string with the text extracted from the given pdf_file using PyPDFium2.\"\"\"\n",
    "    # copied from https://stackoverflow.com/questions/23821204/read-pdf-in-python-and-convert-to-text-in-pdf, first answer\n",
    "    pdf = pdfium.PdfDocument(pdf_file.as_posix())\n",
    "    text = \"\"\n",
    "    for i in range(len(pdf)):\n",
    "        page = pdf.get_page(i)\n",
    "        textpage = page.get_textpage()\n",
    "        text += textpage.get_text()\n",
    "        text += \"\\n\"\n",
    "        textpage.close()\n",
    "        page.close()\n",
    "    pdf.close()\n",
    "    return text\n",
    "\n",
    "def read_pdf_file_write_txt(dest_dir, conversion_method):\n",
    "    \"\"\"Extract the text from the PDF files in the subdirectories of \"./PDF_to_process\".\n",
    "    \n",
    "    The method expexts the PDF files in (direct) subdirectories of \"./PDF_to_process\",\n",
    "    each subdirectory for one group (e.g. \"flyers\").\n",
    "    It writes the extracted text as text files in corresponding subdirectories of dest_dir.\n",
    "    It creates dest_dir and its subdirectories if necessary.\n",
    "    \n",
    "    Parameters:\n",
    "    dest_dir : Path\n",
    "        path where the results shall be stored\n",
    "    conversion_method : Callable[[Path], string]\n",
    "        function that accept a path to a pdf file and returns a string with extracted text \n",
    "    \"\"\"\n",
    "    pdf_files_dir = Path(\"./PDF_to_process\")\n",
    "    assert pdf_files_dir.is_dir()\n",
    "    dest_dir.mkdir(exist_ok=True)\n",
    "    for pdf_subdir in pdf_files_dir.iterdir():\n",
    "        dest_subdir = dest_dir / pdf_subdir.name\n",
    "        dest_subdir.mkdir(exist_ok=True)\n",
    "        for pdf_file in pdf_subdir.iterdir():\n",
    "            text = conversion_method(pdf_file)\n",
    "            txt_file = dest_subdir / (pdf_file.stem + \".txt\")\n",
    "            txt_file.write_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fd3cc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "pypdfium2_result_path = Path(\"./txt_created_with_pypdfium2\")\n",
    "pypdf2_result_path = Path(\"./txt_created_with_pypdf2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "745cb816",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_pdf_file_write_txt(pypdf2_result_path, conversion_with_pypdf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97a8be32",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_pdf_file_write_txt(pypdfium2_result_path, conversion_with_pypdfium2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4e7a76",
   "metadata": {},
   "source": [
    "### Quantitative analysis with <code>SequenceMatcher.ratio()</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "444ac4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_txt(path):\n",
    "    \"\"\"Return the content of the files in the subdirectories of the path given in the argument.\n",
    "    \n",
    "    It expects that there are subdirectories of path containing text files.\n",
    "    It returns a dictionary mapping those subdirectory names to dictionaries\n",
    "    that match the file names (without suffices) to strings with the content of the files,\n",
    "    so the returned nested dictionary represents the directory structure.\n",
    "    \n",
    "    Parameters:\n",
    "    path : Path\n",
    "        path where the content should be loaded from\n",
    "    \n",
    "    Returns:\n",
    "    dict\n",
    "        a nested dictionary containing strings with the file contents\n",
    "    \"\"\"\n",
    "    return {subdir.name:{txt_file.stem:txt_file.read_text() for txt_file in subdir.iterdir()}\n",
    "              for subdir in path.iterdir()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee04e9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "def compare_txt(dict_one, dict_two):\n",
    "    \"\"\"Compare the strings in the given nested dictionries.\n",
    "    \n",
    "    It expectes both dictionaries to be nested with one level,\n",
    "    having identical keywords and that there are strings in the end.\n",
    "    It compares theses strings using difflib.SequenceMatcher.ratio(...).\n",
    "    \n",
    "    Parameters:\n",
    "    dict_one, dict_two: dict[str, dict[str, str]]\n",
    "        nested dictionaries with identical structure containing the files to be compared\n",
    "    \n",
    "    Returns:\n",
    "    dict[str, dict[str, float]]\n",
    "        a nested dictionary with the same structure and the floats returned by\n",
    "        difflib.SequenceMatcher.ratio(...)\n",
    "    \"\"\"\n",
    "    return {group:{filename:SequenceMatcher(a=content, b=dict_two[group][filename]).ratio()\n",
    "                   for filename, content in files.items()}\n",
    "            for group, files in dict_one.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40e05ec6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity measure of the created files:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'flyers': {'bundeswehr': 0.8889301466259725,\n",
       "  'wegweiser_senioren': 0.9595438968062616,\n",
       "  'bahnstadt': 0.9255838880301983},\n",
       " 'scans': {'double_ocr': 0.9810289122690746, 'single_ocr': 0.9478320446314965},\n",
       " 'iban': {'liste1': 0.9995294117647059}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pypdf2_results = load_txt(pypdf2_result_path)\n",
    "pypdfium_results = load_txt(pypdfium2_result_path)\n",
    "print(\"Similarity measure of the created files:\")\n",
    "compare_txt(pypdf2_results, pypdfium_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f649a079",
   "metadata": {},
   "source": [
    "### Qualitative (and further quantitative) analysis\n",
    "\n",
    "#### Flyers\n",
    "\n",
    "SequenceMatcher finds the least similarity in the strings extracted from the Bundeswehr flyer.\n",
    "The Bundeswehr flyer is actually a large table, containing lots of organizations, their addresses, phone numbers, and so on.\n",
    "The cells of the table contain line breaks because their content wouldn't fit into the cells otherwise,\n",
    "but often they don't have any semantic meaning.\n",
    "However, both PyPDFium2 and PyPDf2 reproduces these line breaks in the extracted text.\n",
    "Even worse, PyPDF2 does not introduce any line breaks between the cells, next to the line breaks within the cells, it only introduces line breaks between rows of the table.\n",
    "This leads to severe problems:\n",
    "For example, the last figure of the postal code of the address of the first tank division (\"1. Panzerdivision\") is 3, this figure is the only content of the last line in the corresponding address cell and its e-mail-address, given in the following cell is \"1.PzDivPressestelle@Bundeswehr.org\".\n",
    "This leads to a highly misleading line \"31.PzDivPressestelle@\" in the created text.\n",
    "(The second part of the e-mail address is given in the next line due to a line break in the PDF,\n",
    "but that is the same with PyPDFium2.)\n",
    "Consequently, the text file produced by PyPDFium2 has more lines (20'264 vs. 18'256).\n",
    "\n",
    "The opposite is true for the Bahnstadt flyer (2703 vs. 3029).\n",
    "The reason is probably that PyPDFium2 ignores linebreaks after a hyphen,\n",
    "it replaces the hyphen with some character represendted as an orange dot in Jupyter Notebook.\n",
    "\n",
    "According to SequenceMatcher, the Senioren-Wegweiser strings have the largest similarity.\n",
    "However, the tendency of PyPDFium2 to rather use newlines, already seen in the Bundeswehr flyer, has an even stronger effect here: 3627 vs. 91 lines.\n",
    "The flyer contains subsections, each with post and e-mail addresses and phone numbers of an instiution for elederly people.\n",
    "The phone numbers and the parts of the postal addresses are given in one line each in the PDF document.\n",
    "PyPDF puts them into one line, yet with spaces between them so that they don't get mixed up as it is the case with the Bundeswehr flyer.\n",
    "However, the approach of PyPDFium2 to keep the linebreaks from the PDF\n",
    "so that each phone number, e-mail address and so on stays in a single line is probably way better for further analysis like automated address extraction.\n",
    "\n",
    "#### Scans\n",
    "\n",
    "SequenceMatcher finds a higher similarity for the double_ocr scans than for all flyers.\n",
    "Looking through them manually, one does not find any relevant differences, either.\n",
    "The strings extracted from the single_ocr PDFs one big difference:\n",
    "This time, PyPDF uses way more linebreaks (47 vs. 154)\n",
    "but in neither cases, numbers are mixed up, contrary to the situation with the Bundeswehr flyer.\n",
    "\n",
    "#### IBAN\n",
    "\n",
    "Both methods create very similar strings.\n",
    "The PDF is a table, like the Bundeswehr flyer.\n",
    "In contrary to that, even PyPDFium2 does not set newlines for new table cells.\n",
    "The order of table, footnotes and footer is inverted (relative to the PDF) in both extracted strings,\n",
    "yet there is one important difference between the two methods:\n",
    "PyPDF2 merges the the footnote number one with the the footer, ending with 2021, leading to a date \"1. Januar 20211\" (1st of January, 20211 ...).\n",
    "That's the same problem as with the Bundeswehr flyer.\n",
    "\n",
    "### Decision for one method\n",
    "\n",
    "The files created with PyPDFium2 will be for the further tasks\n",
    "since PyPDF2 mixes up numbers in tables or footers (particularly in the Bundeswehr flyer).\n",
    "\n",
    "However, there is a problem with PyPDFium2:\n",
    "Hyphens that were introduced not for semantic reasons but for line breaks are represented as \"\\x02\" in the resulting string.\n",
    "Therefore, this sequences must be removed before the string can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05277529",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_files_path = pypdfium2_result_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36baa69a",
   "metadata": {},
   "source": [
    "## 3. Extract phone numbers, e-mail addresses and IBANs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d70712d",
   "metadata": {},
   "source": [
    "### (i) Phone numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e62313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# see last parapgraph under \"Decision for a method\"\n",
    "substitute_prog = re.compile(\"\\\\x02\")\n",
    "txt_strings = {group:{filename:substitute_prog.sub(\"\", content) for filename, content in files.items()}\n",
    "              for group, files in load_txt(txt_files_path).items()}\n",
    "\n",
    "ir_result_path = Path(\"./IR_results\") # the extracted phone numbers, URLs and so on will be stored here\n",
    "ir_result_path.mkdir(exist_ok=True)\n",
    "\n",
    "def extract_and_write_results(txt_strings, result_filename, extraction_method):\n",
    "    \"\"\"Extract phone numbers, URLs etc. from the given strings and write them to disk.\n",
    "    \n",
    "    The method calls extraction_method with each string in txt_string as argument,\n",
    "    puts the results in a set (so they will be unique)\n",
    "    and writes them (one instance on a line) to the file under result_filename in ir_result_path.\n",
    "    \n",
    "    Parameters:\n",
    "    txt_string : Iterable[str]\n",
    "        iterable over the strings to process\n",
    "    result_filename : str\n",
    "        name of the file (will be overridden if existing) in ir_result_path\n",
    "        where the results will be stored\n",
    "    extraction_method: Callable[[str], Iterable[str]]\n",
    "        function that extracts the phone numbers, URLs etc. from the string\n",
    "    \"\"\"\n",
    "    result_list = []\n",
    "    for raw_string in txt_strings:\n",
    "        result_list.extend(extraction_method(raw_string))\n",
    "    result_set = set(result_list)\n",
    "    result_string = \"\\n\".join(result_set)\n",
    "    (ir_result_path / result_filename).write_text(result_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c023cf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_numbers_prog = re.compile(r\"(?:\\+ ?|\\(|0 6|0 7|0800-?|116 ?|062|0 ?17|0 ?18|0 ?71)(?:[0-9]*[\\-()/ ]*)+\\n?(?:-? ?[0-9]+[\\- ]?)*[0-9]\")\n",
    "not_digits_prog = re.compile(\"[^0-9+]\")\n",
    "\n",
    "def extract_phone_numbers(raw_string):\n",
    "    \"\"\"Extract phone numbers from the raw_string.\n",
    "    \n",
    "    The returned phone numbers contain only digits and \"+\" (at the beginning like +496224172139).\n",
    "    \n",
    "    Parameters:\n",
    "    raw_string : string\n",
    "        where the phone numbers shall be extracted from\n",
    "    \n",
    "    Returns:\n",
    "        an iterable over the found phone numbers\n",
    "    \"\"\"\n",
    "    raw_results_list = phone_numbers_prog.findall(raw_string)\n",
    "    only_digits = map(lambda raw_result: not_digits_prog.sub(\"\", raw_result), raw_results_list)\n",
    "    return filter(lambda number: len(number) > 5 or number in [\"112\", \"110\", \"19222\"], only_digits)\n",
    "\n",
    "extract_and_write_results(txt_strings[\"flyers\"].values(), \"phone_numbers.txt\", extract_phone_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5890f6b8",
   "metadata": {},
   "source": [
    "### (ii) E-mail-addresses and URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e02ebd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_mail_address_prog = re.compile(r\"(?:(?!\\d\\n)[\\w\\n.-])+@(?:(?!www)[\\w\\n.-])+\\.(?:de|com|org|[a-z\\n]+[a-z])(?:/|\\s|,|\\+)\")\n",
    "\n",
    "def extract_e_mail_addresses(raw_string):\n",
    "    \"\"\"Extract E-mail addresses from the raw string.\n",
    "    \n",
    "    Parameters:\n",
    "    raw_string : string\n",
    "        where the phone numbers shall be extracted from\n",
    "    \n",
    "    Returns:\n",
    "        an iterable over the found phone numbers\n",
    "    \"\"\"\n",
    "    raw_result_list = e_mail_address_prog.findall(raw_string)\n",
    "    def remove_bad_substrings(before):\n",
    "        return before[:-1].replace(\"Heidelberg\\n\", \"\").replace(\"E-Mail\\n\", \"\").replace(\"\\n\", \"\")\n",
    "    return map(remove_bad_substrings, raw_result_list)\n",
    "\n",
    "extract_and_write_results(txt_strings[\"flyers\"].values(), \"e_mail_addresses.txt\", extract_e_mail_addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af0ebc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_prog = re.compile(r\"(?:http://(?:https://)?|www)[\\w\\n.-]+\\.(?:de|com|org|[a-z\\n]+[a-z])(?:/|\\s|,|\\+)\")\n",
    "\n",
    "def extract_urls(raw_string):\n",
    "    \"\"\"Extract URLs from the raw string.\n",
    "    \n",
    "    The method accepts addresses like www.example.com although they are not valid URLs according to RFC 3986.\n",
    "    However, it turns it to well-formatted ULS so in the example case the returned iterator would contain an entry:\n",
    "    http://www.example.com\n",
    "    \n",
    "    Parameters:\n",
    "    raw_string : string\n",
    "        where the phone numbers shall be extracted from\n",
    "    \n",
    "    Returns:\n",
    "        an iterable over the found phone numbers\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for raw_url in url_prog.findall(raw_string):\n",
    "        url = raw_url[:-1].replace(\"\\n\", \"\")\n",
    "        if url[0:15] == \"http://https://\":\n",
    "            result.append(\"http://\" + url[15:])\n",
    "            result.append(\"https://\" + url[15:])\n",
    "        elif url[0:4] == \"http\":\n",
    "            result.append(url)\n",
    "        else:\n",
    "            result.append(\"http://\" + url)\n",
    "    return result\n",
    "\n",
    "extract_and_write_results(txt_strings[\"flyers\"].values(), \"URLs.txt\", extract_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63054d9a",
   "metadata": {},
   "source": [
    "### (iii) IBANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0da9adf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "iban_prog = re.compile(\"[A-Z]{2}[0-9]{2} (?:[A-Z0-9]{4} )*[0-9]{1,4}\")\n",
    "extract_and_write_results(txt_strings[\"iban\"].values(), \"IBAN.txt\", lambda raw_string: iban_prog.findall(raw_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddea8c02",
   "metadata": {},
   "source": [
    "## 4. Use the method from 3. (i) one a new text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b4a997e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01791173263',\n",
       " '062219831331',\n",
       " '01788957264',\n",
       " '01712819736',\n",
       " '017632137783',\n",
       " '01751699490',\n",
       " '018122008708',\n",
       " '01707781800',\n",
       " '01726239609',\n",
       " '01775987162',\n",
       " '017623232774',\n",
       " '01773434363',\n",
       " '01711734982']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(extract_phone_numbers(txt_strings[\"scans\"][\"single_ocr\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac22d5a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['062211383613',\n",
       " '0622143',\n",
       " '062211383620',\n",
       " '06221140714',\n",
       " '062215850930',\n",
       " '0622197370',\n",
       " '0622150259595',\n",
       " '0622160430',\n",
       " '06221604360',\n",
       " '06202859430']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(extract_phone_numbers(txt_strings[\"scans\"][\"double_ocr\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694490a0",
   "metadata": {},
   "source": [
    "Given that the scans were made from phone books, it's rather disappointing that only so few phone numbers were found.\n",
    "On the other hand, this is not a surprise since the regexes are adopted to the flyers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2ca81e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
